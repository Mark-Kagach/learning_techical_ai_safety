# Technical AI Safety Self-Education

## The goal is to master technical AI safety sufficiently to conduct frontier research in a chosen niche.

Between September and December 2025 this repo was about mastering AI/ML techniques to get hired as, broadly, junior ml engineer. From January 2026 I shifted my focus to becoming technical AI safety researcher.


## Solution
The solution is **consistent [deliberate practice](https://www.amazon.com/gp/product/0544947223/)**. It is divided into [theoretical](https://github.com/Mark-Kagach/learning_ml/tree/24fe7c69d1fcb40b3a853f8659e0e7caa4388e28/Theoretical%20Practice) and [technical](https://github.com/Mark-Kagach/learning_ml/tree/24fe7c69d1fcb40b3a853f8659e0e7caa4388e28/Technical%20Practice) parts. This repository is a public practice camp where I log my training sessions. I publish this because, besides the value of signaling, I work better under public accountability. Below I describe my learning approach and some additional details. 

### Learning Algorithm
1. **Understand** important concepts, techniques. Usually means [explaining](https://www.youtube.com/watch?v=_f-qkGJBPts) them in my own words and adding to my notes knowledge base.
2. **Integrate** them. For theory that usually means practicing recalling ([spaced repetition](https://gwern.net/spaced-repetition)) and explaining these concepts from scratch. For techniques that means practicing through exercises from textbooks (e.g. Hands-on ML by Geron Aurelien, LLMs from Scratch etc.), and completing more complex projects with time.

### Details
The main idea is to treat my study with similar attitude as professional athletes treat their [practices](https://open.spotify.com/episode/1V1b314FLv4bn0KbauqvUa?si=dF9lIgVwTFWTmyyWRURUEA&t=4599). (Here are the main books I used to understand what good practice is: Peak, The Art of Learning, Get better at anything, and Ultralearning.)

Important mistake to watch out is taking in too much content without first integrating it one piece at a time. It is important not to move further until you feel solid with the learned content, in the short-run this might be slow, but in the long-run it will pay significant dividends: [Nintil on Bloom's two sigma problem](https://nintil.com/bloom-sigma/).

I also try to heavily triage what I consider relevant theory and techniques to practice based on my goals. (For example, if you want to be an alignment researcher, unlikely you need to know cutting edge computer vision techniques.)

Prior to September 2025 I've done just a few AI/ML projects: CS50ai, Andrew Ng's ML Specialialization, Paul Graham RAG connected to MCP.

Below you can find my weekly log of work hours and what I worked on.

## Weekly Work Log; 2026 Weekly Work Hours

**Feb 2026**
- W6:

**Jan 2026**
- W5: Kept going a bunch of resources to form somewhat good model of all TAIS subfields and subfields within them. Shallow review was quite helpful for that!
- W4: Went through cs2881 Harvard masters course by Boaz Barak on AI safety -- highly recommend! 
- W3: Changed approach from studying bread-first, to more specifically technical ai safety research. General research of everything I can get my hands on about technical ai safety, mainly: bluedot TAIS course, shallow AIS 2025 review, research proposals by anthropic and coefficient giving.
- W2: Finished the first part of Hands-on ML that is about ml! (a lot of ML!) 
- W1: Mostly family travel.

## Weekly Work Log; [2025 Weekly Work Hours](https://docs.google.com/spreadsheets/d/1rfQKYsyOER4DXbrs000tAxtyGI_Syt5L0C22ac5TzqI/)

**Dec 2025**
- W52: Mostly family travel.
- W51: Went in depth through 19th chapter on ML. Kept on going with Hands on ML book, finishing with ML part: SVMs, Decision trees, dim reduction, unsupervised learning...
- W50: Went through all AIMA chapters, broadly capturing (understanding and integrating) main AI subfields: search in simple/complex adversarial environments; logic, knowledge, reasoning, and planning (logical agents, knowledge representation...); uncertain knowledge and reasoning (bayesian networks, decisions in simple/ complex uncertain environments, multiagent decision making).
- W49: Continued focus on mental models that explain big picture of AI and ML. Read first two chapters of AI Modern approach (80 pages). Now focused on having a broad overview of all AI subfields from the book but ML, DL, RL. (Those I'll explore deeply next.)

**Nov 2025**
- W48: Revisited main explanations of computers, ML, and developed framework for differentiating implicit and explicit coding. Wanted to get fundamentals and big picture really right.
- W47: Finally submitted that lovely Coefficient Giving grant: https://www.youtube.com/watch?v=3fMv7pOzPKs
- W46: Mostly family travel.
- W45: Mostly family travel.

**Oct 2025**
- W44: Mainly was writing proposal for Coefficient Giving, and mini burn-out❤️.
- W43: Won AAAA with Elias ($2,500): https://www.linkedin.com/posts/nicholas-gentry-phd_menopause-later-activity-7390066766556856320-EjUN/ https://github.com/EliasSchlie/quantifying-the-value-of-delayed-ovarian-aging
- W42: Started working on the AAAA Hackathon: https://www.hackaging.ai
- W41: Spend most of the time prepping for Coefficient Giving grant (https://www.youtube.com/watch?v=3fMv7pOzPKs), wrote My Evolving Almanack (https://markkagach.substack.com/s/my-evolving-almanack).

**Sep 2025**
- W40: Mostly self-studying ML concepts, explaining them and revisiting past things with flashcards.
- W39: Continued with Kaggle datasets and Hands-on Machine Learning.
- W38: Found it to be too spiky and unfitting for my learning goals, switched to practicing basic Kaggle datasets on my own and Hands-On Machine Learning book.
- W37: Was doing ML Specialization by Andrew Ng.
- W36: Created Paul Graham MCP/ RAG: https://www.youtube.com/watch?v=yWfr8tkJUhA

