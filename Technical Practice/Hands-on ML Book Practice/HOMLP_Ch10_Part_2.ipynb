{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EDjc_aMo474U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchmetrics\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as T"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale=True)])"
      ],
      "metadata": {
        "id": "QfKZ0Ghu5C9q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.serialization import validate_cuda_device\n",
        "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=True, download=True, transform=toTensor\n",
        ")\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root=\"datasets\", train=False, download=True, transform=toTensor\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_data, valid_data = torch.utils.data.random_split(\n",
        "    train_and_valid_data, [55000, 5000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uhj50Hs15C6g",
        "outputId": "eca3089e-8208-4a61-8d4b-93522814f6dd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.5MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.93MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 24.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "PJuEmJ4a5C3R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample, y_sample = train_data[0]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "-Em6Yncc5C0Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2kFVhRNvBlMo",
        "outputId": "32824c80-d05c-494f-a105-cf5ce00efa27"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageCLassifier(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
        "    super().__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(n_inputs, n_hidden1),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_hidden1, n_hidden2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_hidden2, n_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.mlp(X)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = ImageCLassifier(n_inputs =28*28, n_hidden1=300, n_hidden2=100, n_classes=10)\n",
        "xentropy = nn.CrossEntropyLoss()\n",
        "n_epochs = 20"
      ],
      "metadata": {
        "id": "VXlNBkDd5Cxf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train2(model, optimizer, criterion, metric, train_loader, valid_loader,\n",
        "               n_epochs):\n",
        "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
        "    for epoch in range(n_epochs):\n",
        "        total_loss = 0.\n",
        "        metric.reset()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            model.train()\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            metric.update(y_pred, y_batch)\n",
        "        mean_loss = total_loss / len(train_loader)\n",
        "        history[\"train_losses\"].append(mean_loss)\n",
        "        history[\"train_metrics\"].append(metric.compute().item())\n",
        "        history[\"valid_metrics\"].append(\n",
        "            evaluate_tm(model, valid_loader, metric).item())\n",
        "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
        "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
        "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
        "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
        "    return history"
      ],
      "metadata": {
        "id": "5neTI1RQ5CuZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_tm(model, data_loader, metric):\n",
        "    model.eval()\n",
        "    metric.reset()  # reset the metric at the beginning\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in data_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            y_pred = model(X_batch)\n",
        "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
        "    return metric.compute()  # compute the final result at the end\n",
        "\n",
        "    evaluate_tm(model, valid_loader, rmse)"
      ],
      "metadata": {
        "id": "Mp81lXLqDa2A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
        "\n",
        "z = train2(model, optimizer, xentropy, accuracy, train_loader, valid_loader,\n",
        "           n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCW5u0rZ5Crc",
        "outputId": "4d5b4e67-9250-4e33-cc46-7ddd3959489c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, train loss: 0.4074, train metric: 0.8483, valid metric: 0.8518\n",
            "Epoch 2/20, train loss: 0.3639, train metric: 0.8653, valid metric: 0.8576\n",
            "Epoch 3/20, train loss: 0.3360, train metric: 0.8751, valid metric: 0.8562\n",
            "Epoch 4/20, train loss: 0.3162, train metric: 0.8829, valid metric: 0.8710\n",
            "Epoch 5/20, train loss: 0.2996, train metric: 0.8878, valid metric: 0.8730\n",
            "Epoch 6/20, train loss: 0.2851, train metric: 0.8942, valid metric: 0.8734\n",
            "Epoch 7/20, train loss: 0.2730, train metric: 0.8980, valid metric: 0.8604\n",
            "Epoch 8/20, train loss: 0.2620, train metric: 0.9015, valid metric: 0.8786\n",
            "Epoch 9/20, train loss: 0.2527, train metric: 0.9043, valid metric: 0.8728\n",
            "Epoch 10/20, train loss: 0.2435, train metric: 0.9075, valid metric: 0.8700\n",
            "Epoch 11/20, train loss: 0.2348, train metric: 0.9110, valid metric: 0.8726\n",
            "Epoch 12/20, train loss: 0.2282, train metric: 0.9120, valid metric: 0.8870\n",
            "Epoch 13/20, train loss: 0.2222, train metric: 0.9144, valid metric: 0.8848\n",
            "Epoch 14/20, train loss: 0.2155, train metric: 0.9184, valid metric: 0.8852\n",
            "Epoch 15/20, train loss: 0.2080, train metric: 0.9212, valid metric: 0.8770\n",
            "Epoch 16/20, train loss: 0.2017, train metric: 0.9234, valid metric: 0.8856\n",
            "Epoch 17/20, train loss: 0.1977, train metric: 0.9258, valid metric: 0.8880\n",
            "Epoch 18/20, train loss: 0.1910, train metric: 0.9279, valid metric: 0.8878\n",
            "Epoch 19/20, train loss: 0.1869, train metric: 0.9287, valid metric: 0.8896\n",
            "Epoch 20/20, train loss: 0.1806, train metric: 0.9312, valid metric: 0.8898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdKaS1s85Coa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTOu_wlU5ClH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "afXHLE-15CiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D13ELXON5Ce4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bi6YHY7k5Cbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-SMLuE45CYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V_aS1qBG5CVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJWVe9TZ5CS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Hn7PNmc5CM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HonKrePq5CKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MwcS21DQ5CHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9N2Uq7h15CEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AzP8r4lD5CBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c0vDzhKo5B-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIaPAMvO5B6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}