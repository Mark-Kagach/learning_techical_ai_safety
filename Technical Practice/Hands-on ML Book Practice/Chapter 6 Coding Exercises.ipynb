{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Debrief\n",
        "1. Good learning on types of SVM's. I reran notebook with his LinearSVC configuration. Mine wasn't optimized for large datasets.\n",
        "2. He uses MLPClassifier as stacking model, I use random forests. => No, MLP is just another estimator he uses.\n",
        "3. Smart that he looped training estimators, and then printing out their validation scores.\n",
        "4. My trees were significantly underfitting because of max_leafs I set. Even though I set more estimators than him, it didn't help. Makes sense that putting more trees won't help when they are underfitting, as combining trees helps to mitigate variance, not bias. I reran with his configuration.\n",
        "5. He has convoluted notes of exercise 9, main part of which is doing a stacking classifier. The main learning is to use full dataset because stacking classifier uses cross-validation. I lost 10k training examples because I held out validation set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ID1GHPfLRrId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions\n",
        "1. What's the difference between SVC I'm importing, and LinearSVC he is importing?\n",
        "2. My random forests and extra trees are doing much worse than his, by 10-14%! Why is that?\n",
        "\n",
        "### Answers\n",
        "1. Well, that explains my observation that svc training takes too long. LinearSVC is simpler, used for linear classification, and is optimized for large datasets.\n",
        "2. My tree ensembles underfit because of max_leafs set to 16, while his can go as deep as needed. Even though I set 300 estimators vs his 100, they don't cut it, trees are too simple and combining them together doesn't help.Which makes sense as combining trees together doesn't mitigate bias, but mitigates variance.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ROjQ1JH0S1UR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPXNsL-5jQyc"
      },
      "source": [
        "# Exercise 8\n",
        "> Load the MNIST dataset (introduced in Chapter 3), and split it into a training set, a validation set, and a test set (e.g., use 50,000 instances for training, 10,000 for validation, and 10,000 for testing). Then train various classifiers, such as a random forest classifier, an extra-trees classifier, and an SVM classifier. Next, try to combine them into an ensemble that outperforms each individual classifier on the validation set, using soft or hard voting. Once you have found one, try it on the test set. How much better does it perform compared to the individual classifiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Prep"
      ],
      "metadata": {
        "id": "tFWgiCSvYdYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4afff690"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "X, y = mnist.data, mnist.target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BMjsqzIwlxmL"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "collapsed": true,
        "id": "361ef6e4",
        "outputId": "b4c93a6b-01bc-4010-c157-9406062a39e7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_digit(image_data):\n",
        "  image = image_data.reshape(28, 28)\n",
        "  plt.imshow(image, cmap=\"binary\")\n",
        "  #plt.axis(\"off\")\n",
        "  plt.show()\n",
        "\n",
        "plot_digit(X[432])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KU3GTOYAnlb3"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, X_test = X[:50000], X[50000:60000], X[60000:]\n",
        "y_train, y_val, y_test = y[:50000], y[50000:60000], y[60000:]\n",
        "\n",
        "#print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "#print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "#print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Individual Model Training"
      ],
      "metadata": {
        "id": "Dx4FsWBLYWBi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XnOh9FZovM4",
        "outputId": "771ca270-8b51-4fff-9ab7-4ee918b6afe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest validation accuracy: 0.9736\n"
          ]
        }
      ],
      "source": [
        "# random forest tree classifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_val)\n",
        "\n",
        "rf_validation_score = accuracy_score(y_val, y_pred_rf)\n",
        "print(f\"Random Forest validation accuracy: {rf_validation_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqL2rgvGyJ72",
        "outputId": "ced48cda-2a5c-4d8a-b61c-382788726fa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extra Trees validation accuracy: 0.9743\n"
          ]
        }
      ],
      "source": [
        "# extra-trees classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "xt_clf = ExtraTreesClassifier(n_estimators = 100, n_jobs=-1, random_state=42)\n",
        "xt_clf.fit(X_train, y_train)\n",
        "y_pred_xt = xt_clf.predict(X_val)\n",
        "\n",
        "xt_validation_score = accuracy_score(y_val, y_pred_xt)\n",
        "print(f\"Extra Trees validation accuracy: {xt_validation_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68Wr7VrvyK81",
        "outputId": "09c689f0-edc8-43f7-911d-628814af6908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM validation accuracy: 0.8662\n"
          ]
        }
      ],
      "source": [
        "# svm classifier\n",
        "from sklearn.svm import LinearSVC\n",
        "svm_clf = LinearSVC(max_iter=100, tol=20, dual=True, random_state=42)\n",
        "svm_clf.fit(X_train, y_train)\n",
        "y_pred_svm = svm_clf.predict(X_val)\n",
        "\n",
        "svm_validation_score = accuracy_score(y_val, y_pred_svm)\n",
        "print(f\"SVM validation accuracy: {svm_validation_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensembles"
      ],
      "metadata": {
        "id": "L-mYxy8fYSLx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNjY8Qd-zLWl",
        "outputId": "4443a3d5-a693-40df-80e9-bf6334a5cccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier validation accuracy: 0.9737\n"
          ]
        }
      ],
      "source": [
        "# ensemble hard voting\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('svm', svm_clf), ('rf', rnd_clf), ('xt', xt_clf)])\n",
        "\n",
        "voting_clf.fit(X_train, y_train)\n",
        "y_pred_voting = voting_clf.predict(X_val)\n",
        "\n",
        "voting_clf_validation_score = accuracy_score(y_val, y_pred_voting)\n",
        "print(f\"Voting Classifier validation accuracy: {voting_clf_validation_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0mgeRbYyzSA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d24cdd1e-787a-49e5-d737-62977d2dc041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier Soft validation accuracy: 0.9629\n"
          ]
        }
      ],
      "source": [
        "# ensemble soft voting\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Let CalibratedClassifierCV handle the fitting with cross-validation\n",
        "svm_clf_for_soft_voting = CalibratedClassifierCV(\n",
        "    LinearSVC(max_iter=100, tol=20, dual=True, random_state=42),\n",
        "    method='sigmoid',\n",
        "    cv=5  # This will fit the LinearSVC automatically during calibration\n",
        ")\n",
        "\n",
        "voting_clf_soft = VotingClassifier(\n",
        "    estimators=[('rf', rnd_clf), ('xt', xt_clf), ('svm', svm_clf_for_soft_voting)],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "voting_clf_soft.fit(X_train, y_train)\n",
        "y_pred_voting = voting_clf_soft.predict(X_val)\n",
        "\n",
        "voting_clf_soft_validation_score = accuracy_score(y_val, y_pred_voting)\n",
        "print(f\"Voting Classifier Soft validation accuracy: {voting_clf_soft_validation_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "X2b_pvyw0xbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80353353-5a24-43c5-dad5-026794572031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Voting Classifier Soft test accuracy (ensemble): 0.9566\n",
            "\n",
            "Individual Estimator Test Accuracies:\n",
            "rf = 0.968\n",
            "xt = 0.9703\n",
            "svm = 0.9029\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Ensure y_test is of integer type for robust scoring\n",
        "y_test_int = y_test.astype(np.int64)\n",
        "\n",
        "# test set\n",
        "y_pred_voting = voting_clf_soft.predict(X_test)\n",
        "\n",
        "# FIX: Convert y_pred_voting to integer type for correct comparison\n",
        "y_pred_voting_int = y_pred_voting.astype(np.int64)\n",
        "\n",
        "voting_clf_test_score = accuracy_score(y_test_int, y_pred_voting_int)\n",
        "\n",
        "print(f\"Voting Classifier Soft test accuracy (ensemble): {voting_clf_test_score}\")\n",
        "\n",
        "# test set values of each predictor\n",
        "print(\"\\nIndividual Estimator Test Accuracies:\")\n",
        "for name, clf in voting_clf_soft.named_estimators_.items():\n",
        "  # Use y_test_int for scoring individual classifiers\n",
        "  print(name, \"=\", clf.score(X_test, y_test_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLpRKGes8Sfo"
      },
      "source": [
        "# Exercise 9\n",
        "> Exercise: Run the individual classifiers from the previous exercise to make predictions on the validation set, and create a new training set with the resulting predictions: each training instance is a vector containing the set of predictions from all your classifiers for an image, and the target is the image's class. Train a classifier on this new training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "q2lWnsLn8UDt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b312e1-dcd4-4846-b67e-1690c77cebd3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9747"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators= [('rf', rnd_clf), ('xt', xt_clf), ('svm', svm_clf)],\n",
        "    final_estimator=RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    cv=5)\n",
        "stacking_clf.fit(X_train, y_train)\n",
        "stacking_clf.score(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}