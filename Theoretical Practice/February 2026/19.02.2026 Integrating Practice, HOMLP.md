# Goal
The goal is to recall explaining chapter 13 about RNNs, and then chapter 9,10,11.

# Debrief
Overall good recall of past chapters, with noticing and fixing my understanding mistakes for RNNs.

# Notes

So, chapter 13 is about RNNs. Imagine you have sequential data where ordering of instances matters. Say words in a sentences, or any time series like stock price.

Can we use NNs to model them? We can. Would fully connected DNNs work? Mmmm. Actually, I don't remember what they say about this in the textbook, but long-story short they don't really work.  (They even use CNNs for sequential data, but I absolutely didn't go into it, that's all I know.)

How could we give information about the ordering to the neural network? One way is to give to the neuron both the input data, and the output from the past training instance. 

Say you have x_1 and x_2 training instances, and you produce y^hat_1 using x_1. To produce y^hat_2 you give to the neuron both the x_2 and the y^hat_1 info. So you have twice the number of parameters to optimize!

instead of y^hat_1 we tidy up the notation and call it h_1, but these are exactly the same values.

To truly understand RNN you need to see its calculations throughout training instances, and since they are in order, and this data is called time series, we call seeing RNN throughout training instances as unrolling it through time.

I draw a graph for my own understanding*

I made both the simple one neuron example, and also layered RNN.

ðŸ”´ => One question I have is how it works for RNNs with layers and many neurons. Does the neuron receive the outputs of its own exact enouron in the past training example, or does it receive the output of the whole network in the past example. My guess is the value of that particular neuron previously.

=> So, in a multi-layered RNN calculation happens by layer. We feed to neurons the output values of their layer from past training istance. We don't give specific neuron info, or output of the whole network, each neurno gets info about its whole layer activation of past training instance.

> In multi-layer RNNs, each neuron receives information about the entire previous hidden state vector from the prior time stepâ€”not just its own past activation value, and not the full network output from a past training instance.

Okay, that was important to clarify, that's why integration is useful!

Let's move next in our RNN explanations.

The issue with RNNs is that they have awfully short memory, imagine reading a sentence and by its end forgetting how it started, and it has the same issues with vanishing/ exploding gradients.

For gradients regular stuff of better weight initialization, ðŸŸ¡ (forgot what else is there to do) learning rate?.. ... works.

What doesn't work is having nonsaturating positive activation functions like relu. Why? Because if you increase the output of some layer at the initial training instance, it will propagate across all other training instance, compounding on each other. This would cause gradient exploding so training won't work. So we need saturating activation functions like tanh. We also can't use batch normalization as it doesn't really work.

The other issue with deep RNNs, or training them on long sequences, is awful memory. We can improve it significantly by using LSTM architecture which is an improvement on RNN, or GRU which is a simplification improvement on LSTM.

So, how LSTM works? The name is long short term memory, and that sums up the main idea pretty well. We want to have both the stream of short-term memory from past training instance, and of long-term memory. Short term is h_t, long-term is c_t. 

The long-term stream is created by model itself. It learns what information must be preserved, erased, and when it should be read. LSTM cell has 4 fully connected layers within it three of which act as gate controllers, say like deciding what to erase or remember for long-term stream etc. (I intentionally don't go into more details.)

So LSTM outputs two things: h_t and c_t (short-term stream, and long-term stream)

GRU is a simplication improvement on LSTM. It combines two streams into one: h_t, and it has just two fully connected layers, where one is responsible for several gate controllers compared to LSTM.

What else about RNNs. I think that mostly it. Let's do review of it.

ðŸ”´ => Shoot, haven't mentioned entirely there are four types of RNNs: seq-2-seq, seq2vec, vec2seq, encoder-decoder,

ðŸ”´ => I was confusing what is fed into neurons because I was treating yhat as final output of the whole network, not of just some layer, but it can be seen like that too.

But that's generally all I want to remember about RNNs.

---

So, chapter 11 etc.

Chapter 11 is about faster deep neural network training.

So starting with number of layers, depth is exponentially more efficient (neuron number wise) than a single layer because it can build upon its learned representations to create hierarchy of representations from very simple ones to more complex ones. Theoretically nn can approximate any continuous function.

Then we have number of neurons, previously we did descending pyramid with number of neurons so model compresses info and learns higher level representations, but empirically same number of neurons on all hidden layers shows to work just as fine or better. Also you avoid the bottlenecked layer which prevents whole model from learning. You start with giving just a bit too much neurons for network but you can be sure it is powerful enough to model the data, and you slowly increase it to get just right size. This way you ensure model has enough power to learn complex representations. (Neuron's activation functions allow you to basically piece by piece stich neuron values to model the data. The more neurons, the more pieces you could have.)

Then we have ultra important learning rate. Basically to find a good one you start small, increase it by constant factor and plot against loss function. Once loss goes up you stop and take 10x less of that learning rate as a rule of thumb. You also can do learning rate scheduling where you start with big learning rate and slowly decrease it. There are many different ways of doing it.

Aha, lastly batch training vs minibatch. Basically first try batch loading everything you can on gpu ram, do learning rate warmup and you should be fine. If not, do mini batch 32.

If you have time and compute you play with activation functions and optimizers.

(Actually I realized what I'm telling you right now is the end of chapter 10, not chapter 11, as chapter 11 is about speeding up deep nn training. Let me just keep on rolling.)

The issue with deep nn training is exploding/ vanishing gradients as you go back in model's layers noise gets saturated, so training fails. There are several ways to prevent that from happening. First using nonsaturating activation functions like relu, second batch normalization, third better weight initializaion, forth learning rate?

Also we can pick better optimizers than simple gradient descent, let me mention one that matters. Using momentum. Basically think of gradient descent as speed value, momentum calculates acceleration and uses that to change parameters. Acceleration must take into account also past gradient values. Turns out momentum is a more efficient optimizer.

We talked about learning rate scheduling, what else mmm.

Right, reusing lower layers from similar networks, training only the top layers.

---

Chapter 10 is about pytorch fundamentals which are sup useful to repeat!

pytorch in a dl library, its main value prop is that it supports gpus tpus model training, and that it automatically saves autodiff when training model in a computation graph for every parameter which makes afterward backprop calculation efficient and fast.

Its main ds is tensor, multidimensional array, like matrix. Can be one data type at a time, but supports several types: complex > float > integer > bool. If you give it a mix it will revert to the most general one.

It has several useful classes, hte main one being nn module, because it has all methods/things you need for model training, or putting it together with other modules as lego bricks. The trick with it is that it automatically identifies what are parameters given the data you give to it, so for that to work and for it to differentiate parameters with regular tensors you need to wrap parameters in a tensor subsclass called parameter! Super obvious. Because it's a subclass it inherits everything from tensor, but it also gets identified by nn module.

When training a model you first make a prediction (forward), then calculate a loss, then autodiff was calculated for you already during forward pass so you do backward pass, then you take gradient for each parameter and do a gradient descent step, then drop gradients for each parameter for next iteration. (Pytorch accumulates gradients of parameters so you always need to drop them.)

To run inference you need to do it within no_grad condition so that autodiff is not calculated automatically which speeds up inference.

If doing mini-batch training, you have to convert dataset into dataloaders datatype, which if i remember is also just a tensor subclass but it has a few methods which make mini batch training easier, and then you give this dataset to some other methods which assumes you have those methods, and then you can easily train a model. ðŸŸ¡ => poor recall of those details. => dataloader is the class, tensordataset is the datatype.

you also need to upload model to GPU RAM to speed up training, sometimes you can fit the whole model, sometimes not, so you do mini batch training. 

You evaluate models using torchmetrics library, and you also have torchvision library for vision models.

You load and save model just via its weight values, and you load them on the same architecture you make from scratch, this is safer and has no compatibility issues. There are also libraries model load safely. 

You can optimized model running with torchscript.

You also can create custom modules for unique network architecture like wide and deep NNs (there's also variation there...). But the idea is to feed to the output layer also values of lower layers which have simple representations so they can be used for solving the task, which ocassionally is useful.






