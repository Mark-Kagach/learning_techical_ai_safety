# Goal

Finished first two chapters of AI modern approach, they give good mental models for understanding the whole field. 

While my focus is on ML, DL, RL, I think it make sense to have __some clue__ (very exact word choice) about other subfields of AI. 

Think: search in simple and complex environments, adversarial search, constraint satisfaction problems, logical agents, knowledge representation, automated planning, decision making under uncerainty in simple and complex enviroments (bayesian networks, markov models), robotics, computer vision.

__Some clue__ is exactly the level of understanding I want to have. I'm not interested in deep understanding of those subfields because my goal is to focus on ML,DL,RL. But it also seems wrong to have absolutely no idea what those subfields are about.

So it seems to me that a good balance is to spend next 3-5 days understanding their main ideas, but not go into details. The end-goal is to be able to explain those subfields' main ideas simply and how they fit-in with all of the AI field.

How would I do that? AI modern approach seems like the right source. Read most chapters intros and summaries. Make notes on them, use some llms and other online sources. Maybe also listen to notebook lm audio versions of chapters.

Once I'm done with that, I should have both solid mental models for the whole AI field, and general understanding of most subfiels. That should be enough to confidently jump deeply into ML,DL,RL, which would be the next step in syllabus.

(And I'm continuing with reading/listening to non-fiction books (anything that is not a textbook) about the history of the field and anything related when eating, driving, working out. [Getting 25 books under my belt❤️](https://nymag.com/intelligencer/2020/01/kushner-can-make-mid-east-peace-because-hes-read-25-books.html) (in no particular order):
1. The Alignment Problem
2. Genesis
3. Life 3.0
4. The Scaling Era
5. The Big Score
6. The Master Algorithm
7. Genius Makers
8. Supremacy: AI, ChatGPT, and the race that will change the world
9. AI: A Guide for Thinking Humans
10. The Quest for AI: History of Ideas and Achievements
11. Architects of Intelligence
12. Human Compatible
13. AI Superpowers: China, Silicon Valley and the New World 
14. If anyone builds it, everyone dies
15. The Worlds I see
16. AI 2041
17. Atlas of AI
18. A Brief History of Intelligence
19. Nexus
20. ✅Empire of AI
21. ✅Sam Altman, The Optimist
22. ✅Superintelligence ‒ Nick Bostrom
)

# Notes

Here are my "final" notes about panoramic view of AI. I previously called it many names, the big picture mental model, the hanger/ skeleton into which you can put all the rest of ai subfields and theories... But now it is called "panoramic view of AI". It is the spine of the skeleton if you will. We attach right after it my notes on types of task environments, how they are represented, and then types of agent programs and learning agents and you have good overview to go off from. 

Now going for intros and summaries of each subfield and their chapters. 

Notes from remnote:

- Panoramic View of AI
    - AI is a big field that can be daunting to understand, but to make things clear you just need to take a few simple ideas seriously.
    - I think the main problem is that "Artificial Intelligence" is a poor way to group things.
    - Under one umbrella you have everything from: What is intelligence, consciousness and understanding? to: How can we find optimal path in this graph? How can we make computers identifying things in images? Or use language?...
    - 
    - Here's the skeleton of main ideas: 
        - Computers are tools for transforming information from inputs to outputs based on our instructions.
        - AI is part of software engineering ‒ it is concerned with finding right instructions to produce useful outputs. The difference from traditional SE is in types of problems it addresses, and types of instructions it uses.
        - Transforming information can be used to solve most problems, that's why computers are such a powerful tool.
        - To solve problem in our real-world we need to create valid and useful representations of it that we give to computers. Real-world is too big and complex, our computers and techniques are not capable enough to navigate it raw. We create simplified representative environments (Modeling).
        - AI then is about finding transformations to produce outputs (solve problems) navigating this simplified representative environment (Steering).
        - There are different types of environments based on our real-life problems, our choice of techniques for finding solution depends on it. We call program that finds the solution (transformations) agent.
        - Here subfields of AI arise. (Also we can talk about the spectrum of explicit and implicit coding.)
        - 
    - 
    - Great explanation from Perplexity based on my drafts: https://www.perplexity.ai/search/finished-first-two-chapters-of-NU5.gkhuTSqwHQChgOIxCg#4
    - More
        - 1: 
        - To explain AI we need to start with computers. 
        - Computer is a tool people use to transform information. 
        - We give it inputs, it transforms it based on our instructions, and gives back useful outputs. That's it.
        - 
        - 2: 
        - Transforming information is problem solving. (This process is similar to solving a problem.) 
        - You have some inputs, and from them you want to get an output (your goal). 
        - Problem is how do you get from inputs to outputs (aka your goal). Instructions we give to computers is the solution for reaching the goal. 
        - 
        - 3:
        - AI is about coding (instructing) computers.
        - We want to give computer instructions that would make it transform inputs into outputs. 
        - For example we give it a graph of cities, and it tells us the fastest path from point A to point B. Or we give it an image, and it tells us whether there's a bee on it or not.
        - Each of these examples can be seen as a problem we're trying to solve.
        - How AI is different from traditional software engineering? Most of it isn't? Or it is different types of problems? I can see how ML is different, but not as much of how GOFAI is different from traditional SE.
        - 
        - 4:
        - Now let's get more concrete. Imagine you want to drive from San Francisco to New York, and you need to know the route.
        - This is our problem. How can we use computers to help us solve it?
        - Well, we can start by giving it some inputs. What those should be?
        - We need to give it information about our world, so then it could use it to find the route we want.
        - Should we give information about everything we know in the world? All laws of physics, all satellite images, all languages, everything we know about math, movies, all songs and books in the world? 
        - This is really a lot of information, and nearly none of it is important to the problem we're trying to solve ‒ find the route from SF to NY.
        - So here's a really important idea: We need to give computers information that is relevant for the problem we're trying to solve. In our case that probably is the US road map.
        - 
        - We need to describe our real world (specifically things related to our problem) in a way that is representative.
        - But there are many ways of doing it. We could collect images of all roads in US (think Google Maps), or even record thousands of hours of us driving on all of these roads. But that's really a lot of information. Even though it is relevant to our problem, it would be really hard to navigate it and find optimal path to get from SF to NY.
        - So another thing that would be useful for us using computers and manipulating information, is to give as little and simple information that is still representative of the real-world problem we're trying to solve. So: simplicity and representativeness.  
        - That's the information we want to give to our dear computer to help us out.
        - 
        - 5: 
        - Now here comes coding or AI.
        - We have given simple but representative information about US road map and now we want to find the optimal route from SF to NY.
        - Finding the route, or transformation to get from SF to NY is the question of coding/ AI. 
        - Now we also can talk about AI as agents and environments.
        - Then we can mention the difference between implicit and explicit coding.
        - And then how subfields are just different approaches/ tools for navigating environments (that correspond to real-life problem).
        - 
        - Agents and Environments
        - Based on problem type and environment you choose different tools (subfiels of ai) to code agent.
        - Implicit vs Explicit Coding
        - 
    - Alright, now we can talk in more details what types of environments there are, and what types of AI techniques we can use.
    - 

--

Alright, the goal is to understand how all subfiels of AI are connected, to see the big picture. To have a mental model into which I can put all the subfiels in neat order and see how they are connected.

For that we'll use AIMA chapters, we'll take aside robotics, computer vision and NLP. So the four sub-fields of AI we'll talk about is Search, Logic-Based Agents, Uncertain Knowledge and Reasoning, and Machine Learning.

1. Search
2. Logic-Based Agents
3. Uncertain Knowledge and Reasoning 
4. Machine Learning

The unifying framework that AIMA talks about in AI is about the creation of agents that navigate environment to achieve their goals. 

This is just another way to phrase what we've talked about with coding computers of inputs => transformations => outputs.

Agent-based view of AI is not fundamental, but a useful perspective from which one can understand the field.

(In fact, I think my definition of explicit vs implicit coding is a much more clarifying pespective from which to understand the field of AI. 

Mainly it seems to me because it doesn't get swamped by discussions of unresolved questions like: What constitutes intelligence? What constitutes understanding? What is consciousness? Where many people waste myriad of hours debating it when we practically have no good theory about it so you might as well just move on.

And from explicit vs implicit coding, approach of learning algorithms (i.e. ML) is the one that trully stands out. While GOFAI is just another version of good old software engineering.
)

So while we can talk about AI from perspective of implicit vs explicit coding (and input=> transformations => output), we can also talk from the perspective of creating agents that navigate some environment to achieve goals.

In that sense, agent has to find (or we program it explicitly to find) right transformations to navigate its environment to reach the goal.

Subfields of AI then, are different approaches we can use to program agents (explicitly or not) __based on the environment__ they have to operate it.

So if we come back to our steps of any ML project: 1. Problem 2. Data 3. Model 4. Deployment; we can see we always start with the problem we are trying to solve.

Once we understand the problem we can think of how to solve it. Say this is a problem that is solvable with AI tools. We then would have to choose what AI tools to use to solve it, is it search, logical agents, probabilistic hand-architectures, or ml?

How would I tie this idea to environment and agents? 

We can simplify our real-life problems (make it simpler, more abstract, less details to keep track of, make a small simulated worlds that are still useful and easily transitioning to our real world) by creating smaller, simpler worlds that represent well our real-life problem. And if we find solution in that simpler-smaller-world it would still map well to our real life world and solve the problem we're interested in.

So when we talk about agents navigating environments. Environment is something that we have created that is smaller and simpler than real-life thing, but is still well-representative of the real-world. (And we're trying to make that world as simple as possible while still being representative.)

**Then the question becomes: How can we solve our problem in that smaller-simpler world (environment)?**

That small-simple world still has to be navigated. There are inputs and transformations that would achieve the desired output in that world. Agents are programs that do (find) these transformations in such environments.

When they solve the problem in that small-world (do right transformations or find them). We can take the output and apply it to our problem in the real-world. 

Search, logical agents, probabilistic hand-crafted architectures, are tools for finding solutions in different environments. Sometimes environments are so hard that we can't explicitly program solutions (transformations), so we create a learning algorithm that find it on its own: machine learning.

To illustrate the idea of small world and big real world. Imagine you want navigate through cities. The real world has all these infinite number of details one could keep track of. But you don't need them to find appropriate solution. You can just create a simple graph with distance or driving time between cities and find solution of the shortest path there. Then you can apply that solution to real life and drive that route. You can also add important details to the small-environment to make it more realistic/ useful. For example traffic possibilities, exact road routes, not just city a, b, c. That would make navigating this environment more complex, but also the answer would be more useful. So likely we'll need a more sophisticated program (agent) to get the solution. Maybe instead of previously simple search, we'd need probabilistic hand-crafted architectures.


