# Goal
Study and understand chapter 19 of AI modern approach (depending on how it goes pursue 20, 21, 22, 23).
The process would be: 1. making first round notes on the chapter 2. then revisiting the notes and making more cohesive ones 3. then in last revision understand it all, connect to past knowledge and prepare everything for future maintenance via flashcards.

# Notes

- model is both a hypothesis about the world (environment) and software that solves problems
- 
- Any component of an agent program can be improved by learning. Improvement of components depends on:
- What component to improve.
- What prior knowledge agent has, which influences the model it builds.
- What data and feedback on that data is available.
- 
- Agent's components from chapter 2:
    - A direct mapping from conditions on the current state to actions. 
    - A means to infer relevant properties of the world from the percept sequence. 
    - Information about the way the world evolves and about the results of possible actions the agent can take.
    - Utility information indicating the desirability of world states. 
    - Action-value information indicating the desirability of actions. 
    - Goals that describe the most desirable states. 
    - A problem generator, critic, and learning element that enable the system to improve.4. Utility information indicating the desirability of world states. 5. Action-value information indicating the desirability of actions. 6. Goals that describe the most desirable states. 7. A problem generator, critic, and learning element that enable the system to improve.1. A direct mapping from conditions on the current state to actions. 2. A means to infer relevant properties of the world from the percept sequence. 3. Information about the way the world evolves and about the results of possible actions the agent can take.
    - 
- 
- Prior Knowledge, Transfer Learning, 
- chapter 19 is about problems with Factored Representation Approach ‒ a vector of variable values. It is possible for input to be any kind of data structure, including Atomic Representation Approach and Structured Representation Approach.
- When the output is one of finite set of values, it is Classification, when it is a number, it is Regression (better called function approximation, or numeric prediction).
- 
- The tree types of feedback that can accompany inputs, determine the three main types of learning: Supervised Learning, Unsupervised Learning, and Reinforcement Learning.
    - There are three types of feedback that can accompany the inputs, and that determine the Feedback three main types of learning: 
    - In supervised learning the agent observes input-output pairs and learns a function that maps from input to output. For example, the inputs could be camera images, each one accompanied by an output saying “bus” or “pedestrian,” etc. An output like this is called a label. The agent learns a function that, when given a new image, predicts the appropriate label. In the case of braking actions (component 1 above), an input is the current state (speed and direction of the car, road condition), and an output is the distance it took to stop. In this case a set of output values can be obtained by the agent from its own percepts (after the fact); the environment is the teacher, and the agent learns a function that maps states to stopping distance. 
    - In unsupervised learning the agent learns patterns in the input without any explicit feedback. The most common unsupervised learning task is clustering: detecting potentially useful clusters of input examples. For example, when shown millions of images taken from the Internet, a computer vision system can identify a large cluster of similar images which an English speaker would call “cats.” 
    - In reinforcement learning the agent learns from a series of reinforcements: rewards and punishments. For example, at the end of a chess game the agent is told that it has won (a reward) or lost (a punishment). It is up to the agent to decide which of the actions prior to the reinforcement were most responsible for it, and to alter its actions to aim towards more rewards in the future.There are three types of feedback that can accompany the inputs, and that determine the Feedback three main types of learning: • In supervised learning the agent observes input-output pairs and learns a function that Supervised learning maps from input to output. For example, the inputs could be camera images, each one accompanied by an output saying “bus” or “pedestrian,” etc. An output like this is called a label. The agent learns a function that, when given a new image, predicts Label the appropriate label. In the case of braking actions (component 1 above), an input is the current state (speed and direction of the car, road condition), and an output is the distance it took to stop. In this case a set of output values can be obtained by the agent from its own percepts (after the fact); the environment is the teacher, and the agent learns a function that maps states to stopping distance. • In unsupervised learning the agent learns patterns in the input without any explicit Unsupervised learning feedback. The most common unsupervised learning task is clustering: detecting potentially useful clusters of input examples. For example, when shown millions of images taken from the Internet, a computer vision system can identify a large cluster of similar images which an English speaker would call “cats.” • In reinforcement learning the agent learns from a series of reinforcements: rewards Reinforcement learning and punishments. For example, at the end of a chess game the agent is told that it has won (a reward) or lost (a punishment). It is up to the agent to decide which of the actions prior to the reinforcement were most responsible for it, and to alter its actions to aim towards more rewards in the future.
    - 
- 
- Supervised Learning:
    - https://remnote-user-data.s3.amazonaws.com/WXxlwelXyLSYi0HwG7aP8aaZwnZllGKzb5KuJLoF6IOXD0_rEJFhd8LQL7SVWIHWi5XLDQNZJPssTa-rDT5YyQLKhOYxfRat8Sd9beeRZJjfQx9NFUVvBgjw3As1jOba.pnghttps://remnote-user-data.s3.amazonaws.com/WXxlwelXyLSYi0HwG7aP8aaZwnZllGKzb5KuJLoF6IOXD0_rEJFhd8LQL7SVWIHWi5XLDQNZJPssTa-rDT5YyQLKhOYxfRat8Sd9beeRZJjfQx9NFUVvBgjw3As1jOba.png
    - 
    - Hypothesis Function h
    - Hypothesis Space \mathcal{H}
    - Ground Truth ‒ y(i)
    - 
    - How do we choose the Hypothesis Space \mathcal{H}?
        - We might have some Prior Knowledge about the process that generated data (phenomena).
        - We also might perform Data Exploration.
        - 
    - How do we choose a good Hypothesis Function h from the Hypothesis Space \mathcal{H}?
        - We could hope for Consistent Function where h(x_i) = y_i of the Training Set.
        - But we're unlikely to get that, especially with continuous-valued outputs. So instead we aim for Best-Fit Function.
        - 
    - 
    - The true measure of a Hypothesis Function h is not how it performs on the Training Set, but how well it handles inputs it hasn't seen, i.e. Test Set (x_i, y_i) pairs. 
    - We say Hypothesis Generalizes if it accurately predicts outputs of the test set.
    - The Hypothesis Function h that Learning Algorithm discovers depends on the Hypothesis Space \mathcal{H} it considers and on the given Training Set, see indented picture.
        - https://remnote-user-data.s3.amazonaws.com/OJxNWyEFtWflsIsG76Aj8psZKXoXKJ01p6gb0JxdCI8Fhom07HGJtlGL30qZGXAgOGZnlF6dZrmxQEvQPjCdB0GvPjK-P0mHdcUpgM7h_bzvHJs-DuodgddW3Js23dTy.pnghttps://remnote-user-data.s3.amazonaws.com/KoyFwk9WjHSXVespYs9QVXIDIYRAdmzycXardLQOuaJihSHEeCpJG6mj5r98-aj_4B59DWQodIv0uqREFvCSBcw5f-bw3L2DAMI4y2MCxm8Vqh4jWwZJCv2YhNYgNdbv.pnghttps://remnote-user-data.s3.amazonaws.com/KoyFwk9WjHSXVespYs9QVXIDIYRAdmzycXardLQOuaJihSHEeCpJG6mj5r98-aj_4B59DWQodIv0uqREFvCSBcw5f-bw3L2DAMI4y2MCxm8Vqh4jWwZJCv2YhNYgNdbv.pnghttps://remnote-user-data.s3.amazonaws.com/OJxNWyEFtWflsIsG76Aj8psZKXoXKJ01p6gb0JxdCI8Fhom07HGJtlGL30qZGXAgOGZnlF6dZrmxQEvQPjCdB0GvPjK-P0mHdcUpgM7h_bzvHJs-DuodgddW3Js23dTy.png
        - 
    - 
    - Bias ‒ the tendency of Hypothesis Function to deviate from expected value when averaged over different Training Sets.
    - Bias results often from restrictions imposed by the Hypothesis Space. For example linear functions introduces strong constraints, only straight lines are considered.
        - By bias we mean (loosely) the tendency of a predictive hypothesis to deviate from the expected value when averaged over different training sets. Bias often results from restrictions imposed by the hypothesis space. For example, the hypothesis space of linear functions induces a strong bias: it only allows functions consisting of straight lines. If there are any patterns in the data other than the overall slope of a line, a linear function will not be able to represent those patterns. We say that a hypothesis is underﬁtting when it fails to ﬁnd a pattern in the data. On the other hand, the piecewise linear function has low bias; the shape of the function is driven by the data.imposed by the hypothesis space. For example, the hypothesis space of linear functions induces a strong bias: it only allows functions consisting of straight lines. If there are any patterns in the data other than the overall slope of a line, a linear function will not be able to represent those patterns. We say that a hypothesis is underﬁtting when it fails to ﬁnd a Underﬁtting pattern in the data. On the other hand, the piecewise linear function has low bias; the shape of the function is driven by the data.By bias we mean (loosely) the tendency of a predictive hypothesis to deviate from theBias expected value when averaged over different training sets. Bias often results from restrictions
        - 
    - Hypothesis Function is Underfitting when it cannot find pattern in the Training Set (data).
    - 
    - Variance ‒ the amount of change in Hypothesis Function due to fluctuations in Training Set.
        - By variance we mean the amount of change in the hypothesis due to ﬂuctuation in the training data. The two rows of Figure 19.1 represent data sets that were each sampled from the same f (x) function. The data sets turned out to be slightly different. For the ﬁrst three columns, the small difference in the data set translates into a small difference in the hypothesis. We call that low variance. But the degree-12 polynomials in the fourth column have high variance: look how different the two functions are at both ends of the x-axis. Clearly, at least one of these polynomials must be a poor approximation to the true f (x). We say a function is overﬁtting the data when it pays too much attention to the particular data set it is trained on, causing it to perform poorly on unseen data.By variance we mean the amount of change in the hypothesis due to ﬂuctuation in the Variance training data. The two rows of Figure 19.1 represent data sets that were each sampled from the same f (x) function. The data sets turned out to be slightly different. For the ﬁrst three columns, the small difference in the data set translates into a small difference in the hypothesis. We call that low variance. But the degree-12 polynomials in the fourth column have high variance: look how different the two functions are at both ends of the x-axis. Clearly, at least one of these polynomials must be a poor approximation to the true f (x). We say a function is overﬁtting the data when it pays too much attention to the particular data set it is trained Overﬁtting on, causing it to perform poorly on unseen data.
        - 
    - We say Hypothesis Function is Overfitting when it pays too much attention to particular data set it is trained on, causing it to perform poorly on unseen data, see 12-degree polynomial on the indented picture.
        - https://remnote-user-data.s3.amazonaws.com/OJxNWyEFtWflsIsG76Aj8psZKXoXKJ01p6gb0JxdCI8Fhom07HGJtlGL30qZGXAgOGZnlF6dZrmxQEvQPjCdB0GvPjK-P0mHdcUpgM7h_bzvHJs-DuodgddW3Js23dTy.pnghttps://remnote-user-data.s3.amazonaws.com/OJxNWyEFtWflsIsG76Aj8psZKXoXKJ01p6gb0JxdCI8Fhom07HGJtlGL30qZGXAgOGZnlF6dZrmxQEvQPjCdB0GvPjK-P0mHdcUpgM7h_bzvHJs-DuodgddW3Js23dTy.png
        - 
    - 
    - Bias-Variance Tradeoff ‒ a choice between more complex, low-bias hypotheses that ﬁt the training data well and simpler, low-variance hypotheses that may generalize better.a choice between more complex, low-bias hyBias–variance tradeoﬀ potheses that ﬁt the training data well and simpler, low-variance hypotheses that may generalize better.
        - Albert Einstein said in 1933, “the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.” In other words, Einstein recommends choosing the simplest hypothesis that matches the data. This principle can be traced further back to the 14th-century English philosopher William of Ockham. His principle that “plurality [of entities] should not be posited without necessity” is called Ockham's Razor because it is used to “shave off” dubious explanations. (Occam is a misspelling of Ockham.)
        - Deﬁning simplicity is not easy. It seems clear that a polynomial with only two parameters is simpler than one with thirteen parameters. We will make this intuition more precise in Section 19.3.4. However, in Chapter 22 we will see that deep neural network models can often generalize quite well, even though they are very complex—some of them have billions of parameters. So the number of parameters by itself is not a good measure of a model’s ﬁtness. Perhaps we should be aiming for “appropriateness,” not “simplicity” in a model class. We will consider this issue in Section 19.4.1.Albert Einstein said in 1933, “the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience.” In other words, Einstein recommends choosing the simplest hypothesis that matches the data. This principle can be traced further back to the 14th-century English philosopher William of Ockham.2 His principle that “plurality [of entities] should not be posited without necessity” is called Ockham’s razor because it is used to “shave off” dubious explanations. Deﬁning simplicity is not easy. It seems clear that a polynomial with only two parameters is simpler than one with thirteen parameters. We will make this intuition more precise in Section 19.3.4. However, in Chapter 22 we will see that deep neural network models can often generalize quite well, even though they are very complex—some of them have billions of parameters. So the number of parameters by itself is not a good measure of a model’s ﬁtness. Perhaps we should be aiming for “appropriateness,” not “simplicity” in a model class. We will consider this issue in Section 19.4.1.
        - 
    - 
    - When picking Hypothesis Function we can even choose the most probable function Hypothesis h^* 
        - https://remnote-user-data.s3.amazonaws.com/I9_d-_dQLzydh5nuX_HQLrZkvzIyI19MF8mEkSTQISNRPnEtG9Vx6hnRYkI9wzSvGtdXtCx6J2FizmI_4BjpFCmcN2GPst7GE_BwVD_DNo7QgBTCr1gh44PvfaVivjC9.pnghttps://remnote-user-data.s3.amazonaws.com/19DFMonRvOyFa7mnAJCaSLZ4EFBJvG1NUu66vRp8iTubPfxAYoXtomY1kIYJKl9r_SwBnlJTMh1ZoeF_XnUsdB-n1j8SZibDIvzkKFZ1l0F5q2scDEtWYLaSGrvtUg53.pnghttps://remnote-user-data.s3.amazonaws.com/19DFMonRvOyFa7mnAJCaSLZ4EFBJvG1NUu66vRp8iTubPfxAYoXtomY1kIYJKl9r_SwBnlJTMh1ZoeF_XnUsdB-n1j8SZibDIvzkKFZ1l0F5q2scDEtWYLaSGrvtUg53.pnghttps://remnote-user-data.s3.amazonaws.com/I9_d-_dQLzydh5nuX_HQLrZkvzIyI19MF8mEkSTQISNRPnEtG9Vx6hnRYkI9wzSvGtdXtCx6J2FizmI_4BjpFCmcN2GPst7GE_BwVD_DNo7QgBTCr1gh44PvfaVivjC9.png
        - 
    - 
    - 
- 
- Why not let \mathcal{H} be the class of all computer programs, or all Turing machines?
    - Because there is a tradeoff between the Expressiveness of a Hypothesis Space, and the Computational Complexity of finding a good Hypothesis Function within it ‒ Expressiveness-Complexity Tradeoff.
    - For example, ﬁtting a straight line to data is an easy computation; ﬁtting high-degree polynomials is somewhat harder; and ﬁtting Turing machines is undecidable. A second reason to prefer simple hypothesis spaces is that presumably we will want to use h after we have learned it, and computing h(x) when h is a linear function is guaranteed to be fast, while computing an arbitrary Turing machine program is not even guaranteed to terminate. 
    - For these reasons, most work on learning has focused on simple representations. In recent years there has been great interest in deep learning (Chapter 22), where representations are not simple but where the h(x) computation still takes only a bounded number of steps to compute with appropriate hardware. 
    - We will see that the expressiveness–complexity tradeoff is not simple: it is often the case, as we saw with ﬁrst-order logic in Chapter 8, that an expressive language makes it possible for a simple hypothesis to ﬁt the data, whereas restricting the expressiveness of the language means that any consistent hypothesis must be complex.For example, ﬁtting a straight line to data is an easy computation; ﬁtting high-degree polynomials is somewhat harder; and ﬁtting Turing machines is undecidable. A second reason to prefer simple hypothesis spaces is that presumably we will want to use h after we have learned it, and computing h(x) when h is a linear function is guaranteed to be fast, while computing an arbitrary Turing machine program is not even guaranteed to terminate. For these reasons, most work on learning has focused on simple representations. In recent years there has been great interest in deep learning (Chapter 22), where representations are not simple but where the h(x) computation still takes only a bounded number of steps to compute with appropriate hardware. We will see that the expressiveness–complexity tradeoff is not simple: it is often the case, as we saw with ﬁrst-order logic in Chapter 8, that an expressive language makes it possible for a simple hypothesis to ﬁt the data, whereas restricting the expressiveness of the language means that any consistent hypothesis must be complex.
    - Wow.
    - 
- 
- Example Problem: Restaurant Waiting
    - https://remnote-user-data.s3.amazonaws.com/4HMGeU7rr718yRMUFLB2E-T6G1UoUT5Lx1oORDyf7bUaD88lSfjFyWN-kU0quesrZUE0-xhNM1hfAjnly7MQnl3zEJXP_cyvo7DqL_8s7PYViuCViNeT5PUC68Y5xkS8.pnghttps://remnote-user-data.s3.amazonaws.com/Kq4r2PBx1WUqMPmBm67i27GhJKDq-WiRa1Fo4Mp6B2r6z0P5nwDPWz8z-1KQ8zSPPpy8B3HbxN5CWihsLGY4XT58vUiVkhvKndmOdmFJMllKCdrurrVXpr5xgPFvq1c2.pnghttps://remnote-user-data.s3.amazonaws.com/Kq4r2PBx1WUqMPmBm67i27GhJKDq-WiRa1Fo4Mp6B2r6z0P5nwDPWz8z-1KQ8zSPPpy8B3HbxN5CWihsLGY4XT58vUiVkhvKndmOdmFJMllKCdrurrVXpr5xgPFvq1c2.pnghttps://remnote-user-data.s3.amazonaws.com/4HMGeU7rr718yRMUFLB2E-T6G1UoUT5Lx1oORDyf7bUaD88lSfjFyWN-kU0quesrZUE0-xhNM1hfAjnly7MQnl3zEJXP_cyvo7DqL_8s7PYViuCViNeT5PUC68Y5xkS8.png
    - 
    - 
    - 
- 
- Decision Tree
    - Decision Tree is a representation of a function that maps a vector of variable values to a single output value ‒ a "decision".
    - The "decision" is reached through a sequence of tests, starting at the root, and following the appropriate branch until final leaf with output value is reached.
    - Each test (node) checks the value of one of the input variables.
    - Input and output values can be discrete or continuous.
    - 
    - Example of a Decision Tree:
        - https://remnote-user-data.s3.amazonaws.com/13EQNosDbImb_VnFsKbk5BMPaN2WJblXNINtBb7u3olZXZSulM1Ft_c4LaOckbM5rXGIR-dx5N7QjSoysqSq0b63uICQolcSgLRek5qwuzSVz76pGiSpEvlt-w3pzLLa.pnghttps://remnote-user-data.s3.amazonaws.com/13EQNosDbImb_VnFsKbk5BMPaN2WJblXNINtBb7u3olZXZSulM1Ft_c4LaOckbM5rXGIR-dx5N7QjSoysqSq0b63uICQolcSgLRek5qwuzSVz76pGiSpEvlt-w3pzLLa.png
        - 
    - For many problems, the decision tree format yields a nice, concise, understandable result. Indeed, many “How To” manuals (e.g., for car repair) are written as decision trees.For many problems, the decision tree format yields a nice, concise, understandable result. Indeed, many “How To” manuals (e.g., for car repair) are written as decision trees.
    - 
    - With real-valued attributes, the function y > A1 + A2 is hard to represent with a decision tree because the decision boundary is a diagonal line, and all decision tree tests divide the space up into rectangular, axis-aligned boxes. We would have to stack a lot of boxes to closely approximate the diagonal line. In other words, decision trees are good for some kinds of functions and bad for others.With real-valued attributes, the function y > A1 + A2 is hard to represent with a decision tree because the decision boundary is a diagonal line, and all decision tree tests divide the space up into rectangular, axis-aligned boxes. We would have to stack a lot of boxes to closely approximate the diagonal line. In other words, decision trees are good for some kinds of functions and bad for others.
    - Is there any kind of representation that is efﬁcient for all kinds of functions? Unfortunately, the answer is no—there are just too many functions to be able to represent them all with a small number of bits. Even just considering Boolean functions with n Boolean attributes, the truth table will have 2^n rows, and each row can output true or false, so there are 2^{2^n} different functions. With 20 attributes there are 2^{1,048,576} ≈ 10^{300,000} functions, so if we limit ourselves to a million-bit representation, we can’t represent all these functions.Is there any kind of representation that is efﬁcient for all kinds of functions? Unfortunately, the answer is no—there are just too many functions to be able to represent them all with a small number of bits. Even just considering Boolean functions with n Boolean attributes, the truth table will have 2n rows, and each row can output true or false, so there are 22n different functions. With 20 attributes there are 21,048,576 ≈ 10300,000 functions, so if we limit ourselves to a million-bit representation, we can’t represent all these functions.
    - 
    - We want to ﬁnd a tree that is consistent with the examples in Figure 19.2 and is as small as possible. Unfortunately, it is intractable to ﬁnd a guaranteed smallest consistent tree. But with some simple heuristics, we can efﬁciently ﬁnd one that is close to the smallest.We want to ﬁnd a tree that is consistent with the examples in Figure 19.2 and is as small as possible. Unfortunately, it is intractable to ﬁnd a guaranteed smallest consistent tree. But with some simple heuristics, we can efﬁciently ﬁnd one that is close to the smallest.
    - The LEARN-DECISION-TREE algorithm adopts a Greedy Divide-and-Conquer Strategy: always test the most important attribute ﬁrst, then recursively solve the smaller subproblems that are deﬁned by the possible results of the test. By “most important attribute,” we mean the one that makes the most difference to the classiﬁcation of an example. That way, we hope to get to the correct classiﬁcation with a small number of tests, meaning that all paths in the tree will be short and the tree as a whole will be shallow.The LEARN-DECISION-TREE algorithm adopts a greedy divide-and-conquer strategy: always test the most important attribute ﬁrst, then recursively solve the smaller subproblems that are deﬁned by the possible results of the test. By “most important attribute,” we mean the one that makes the most difference to the classiﬁcation of an example. That way, we hope to get to the correct classiﬁcation with a small number of tests, meaning that all paths in the tree will be short and the tree as a whole will be shallow.
    - 
    - We can evaluate the performance of a learning algorithm with a learning curve, as shown in Figure 19.7. For this ﬁgure we have 100 examples at our disposal, which we split randomly into a training set and a test set. We learn a hypothesis h with the training set and measure its accuracy with the test set. We can do this starting with a training set of size 1 and increasing one at a time up to size 99. For each size, we actually repeat the process of randomly splitting into training and test sets 20 times, and average the results of the 20 trials. The curve shows that as the training set size grows, the accuracy increases. (For this reason, learning curves are also called happy graphs.) In this graph we reach 95% accuracy, and it looks as if the curve might continue to increase if we had more data.We can evaluate the performance of a learning algorithm with a learning curve, as shown Learning curve in Figure 19.7. For this ﬁgure we have 100 examples at our disposal, which we split randomly into a training set and a test set. We learn a hypothesis h with the training set and measure its accuracy with the test set. We can do this starting with a training set of size 1 and increasing one at a time up to size 99. For each size, we actually repeat the process of randomly splitting into training and test sets 20 times, and average the results of the 20 trials. The curve shows that as the training set size grows, the accuracy increases. (For this reason, learning curves are also called happy graphs.) In this graph we reach 95% accuracy, and it looks as if the Happy graphs curve might continue to increase if we had more data.
    - 
    - Our Decision Tree Learning Algorithm chooses variables with the highest IMPORTANCE. We measure it via Information Gain, which is defined through Entropy ‒ the fundamental quantity in Information Theory .
    - Entropy is a measure of uncertainty of a random variable; the more information, the less entropy. (White noise is maximum entropy.) 
    - A random variable with only one possible value—a coin that always comes up heads—has no uncertainty and thus its entropy is deﬁned as zero. A fair coin is equally likely to come up heads or tails when ﬂipped, and we will soon show that this counts as “1 bit” of entropy. The roll of a fair four-sided die has 2 bits of entropy, because there are 22 equally probable choices.A fair coin is equally likely to come up heads or tails when ﬂipped, and we will soon show that this counts as “1 bit” of entropy. The roll of a fair four-sided die has 2 bits of entropy, because there are 22 equally probable choices.
        - https://remnote-user-data.s3.amazonaws.com/GAP3_L4iAbiYZENHA_Fv3uazhs5-AnvMxJIUrdE0LIRWXRMfkLsL15Btsar96MCSp_TYCV-Y7bibyRuZ5Plqr9XZy-dOj1vFkkHAlf-O08MdHAPRyj9lXFubNNoNwSua.pnghttps://remnote-user-data.s3.amazonaws.com/fqjimilFOJeGFUbEYQzGFoCUnYDbbP4wdqZwIb1yCR7OLgTSM1U3e6fqhGE5B9EDPmSLEZvipaOmC9BZjgiUE5qCbjlWdVmzvfm2CVDXsoGDLBOVxVRR93p8QEFlg8hU.pnghttps://remnote-user-data.s3.amazonaws.com/GAP3_L4iAbiYZENHA_Fv3uazhs5-AnvMxJIUrdE0LIRWXRMfkLsL15Btsar96MCSp_TYCV-Y7bibyRuZ5Plqr9XZy-dOj1vFkkHAlf-O08MdHAPRyj9lXFubNNoNwSua.pnghttps://remnote-user-data.s3.amazonaws.com/fqjimilFOJeGFUbEYQzGFoCUnYDbbP4wdqZwIb1yCR7OLgTSM1U3e6fqhGE5B9EDPmSLEZvipaOmC9BZjgiUE5qCbjlWdVmzvfm2CVDXsoGDLBOVxVRR93p8QEFlg8hU.png
        - 
    - Now let's connect Entropy and Decision Tree Learning Algorithm choosing variables with the highest importance, i.e. Information Gain:
        - https://remnote-user-data.s3.amazonaws.com/FglgTGPnY1itVAuXn-IE70Cuccifv8JOrwr03eTypSu7w63GHZ36l0hc1aRl4mjTgGfdGY2SeJA_9Gl111YOpmbYDO6rxu_7hCDZ3DGcuN1Age11CmzwIP32j3Rx-sT1.pnghttps://remnote-user-data.s3.amazonaws.com/FglgTGPnY1itVAuXn-IE70Cuccifv8JOrwr03eTypSu7w63GHZ36l0hc1aRl4mjTgGfdGY2SeJA_9Gl111YOpmbYDO6rxu_7hCDZ3DGcuN1Age11CmzwIP32j3Rx-sT1.png
        - 
    - 
    - Generalization and Overfitting 
    - Decision Tree Pruning, \mathcal{X}^2 Pruning, Early Stopping
        - https://remnote-user-data.s3.amazonaws.com/FglgTGPnY1itVAuXn-IE70Cuccifv8JOrwr03eTypSu7w63GHZ36l0hc1aRl4mjTgGfdGY2SeJA_9Gl111YOpmbYDO6rxu_7hCDZ3DGcuN1Age11CmzwIP32j3Rx-sT1.pnghttps://remnote-user-data.s3.amazonaws.com/NZgmcqclWP5GMz6Dpf1F6FLQAHPriZIvotllks6auhgMr4RjKVzJMzGnq01jmJnng1wsUmp_7jrSKGMd53O8r5RycQoc4_swWylAnCdoBe4upxx6EJ1ZOfD-Yf0sMYzx.pnghttps://remnote-user-data.s3.amazonaws.com/NZgmcqclWP5GMz6Dpf1F6FLQAHPriZIvotllks6auhgMr4RjKVzJMzGnq01jmJnng1wsUmp_7jrSKGMd53O8r5RycQoc4_swWylAnCdoBe4upxx6EJ1ZOfD-Yf0sMYzx.pnghttps://remnote-user-data.s3.amazonaws.com/FglgTGPnY1itVAuXn-IE70Cuccifv8JOrwr03eTypSu7w63GHZ36l0hc1aRl4mjTgGfdGY2SeJA_9Gl111YOpmbYDO6rxu_7hCDZ3DGcuN1Age11CmzwIP32j3Rx-sT1.png
        - 
    - Wide application examples of Decision Trees:
        - https://remnote-user-data.s3.amazonaws.com/_UcW6T83i433IDMGbxu7s0PKb3X5pzbeqsg9kJmuVPb55JkAVyCsYlOogQ3yBdpLvfI2u0900c386N8viPI0NuDaopiHIxbluIEf9gUM4aqfCZPrePOmkZcWDyxH1LEu.pnghttps://remnote-user-data.s3.amazonaws.com/4HJSoG7ZwfNo5aDz5mETc7SveiTxvvJvSDGMhbul4hM8IncK4-0oEPu4APvOrM3Qb9KayFtLI-TxMElqHHNWFiztllefOOnGd3VjUXdfRzyKldEQ9bBBXpUTsyF9I7pG.pnghttps://remnote-user-data.s3.amazonaws.com/4HJSoG7ZwfNo5aDz5mETc7SveiTxvvJvSDGMhbul4hM8IncK4-0oEPu4APvOrM3Qb9KayFtLI-TxMElqHHNWFiztllefOOnGd3VjUXdfRzyKldEQ9bBBXpUTsyF9I7pG.pnghttps://remnote-user-data.s3.amazonaws.com/_UcW6T83i433IDMGbxu7s0PKb3X5pzbeqsg9kJmuVPb55JkAVyCsYlOogQ3yBdpLvfI2u0900c386N8viPI0NuDaopiHIxbluIEf9gUM4aqfCZPrePOmkZcWDyxH1LEu.png
        - 
    - 
- 
- Model Selection and Hyperparameter Optimization
    - Stationary Assumption ‒ assumption that all future example will be like the past one, that is, they are Independent and Identically Distributed.
        - https://remnote-user-data.s3.amazonaws.com/tv3179g_RPa-wzIQo2OgxeykRin2YKWyAQU97OvMY39oMiutqM9LxTL2-hT49HwK-ZJFon9Ne6nHaiE8xgxSRIJkBwwFVDY8uKZ5PJuNP-P0i9D96DMocxxLmB1AA2hb.pnghttps://remnote-user-data.s3.amazonaws.com/tv3179g_RPa-wzIQo2OgxeykRin2YKWyAQU97OvMY39oMiutqM9LxTL2-hT49HwK-ZJFon9Ne6nHaiE8xgxSRIJkBwwFVDY8uKZ5PJuNP-P0i9D96DMocxxLmB1AA2hb.png
    - Optimal Fit ‒ Hypothesis Function that minimizes the Error Rate. Error rate comparing Test Set and predictions made by the hypothesis.
        - https://remnote-user-data.s3.amazonaws.com/PjKrIWpJelyVRTsUKYT6ZdywhbHS2ZSeKP8WUqAIDaP0HE7f-rXlFHswVAXrDgKmiSGiUuk7bp7FefeNSmRqNb7cmvgDuG9disKRWEK55Ziy7Lvk7vZ77u51TTndwXOe.pnghttps://remnote-user-data.s3.amazonaws.com/PjKrIWpJelyVRTsUKYT6ZdywhbHS2ZSeKP8WUqAIDaP0HE7f-rXlFHswVAXrDgKmiSGiUuk7bp7FefeNSmRqNb7cmvgDuG9disKRWEK55Ziy7Lvk7vZ77u51TTndwXOe.png
        - 
    - Training Set is used to learn the Hypothesis Function, Test Set to evaluate it.
    - Hyperparameters ‒ parameters of the Model Class (like decision trees, or polynomial equations).
        - https://remnote-user-data.s3.amazonaws.com/nuptg9NE-HE4U9iy0r2JVC67leN8IQRp6Qk0Gd5LXE9rPU-6yWOerMNiuYTmfX69plfrA5vhIymmPy_CLTNNXNdXOp7x-R6Y0-kv9qdEai_H20ChgQctURPwliRPNNQM.pnghttps://remnote-user-data.s3.amazonaws.com/nuptg9NE-HE4U9iy0r2JVC67leN8IQRp6Qk0Gd5LXE9rPU-6yWOerMNiuYTmfX69plfrA5vhIymmPy_CLTNNXNdXOp7x-R6Y0-kv9qdEai_H20ChgQctURPwliRPNNQM.png
        - 
    - But when tweaking Hyperparameters engineer could overoptimize for the Test Set, so we have also Validation Set that evaluates Hypothesis Function h before checking final best version against the test set.
        - https://remnote-user-data.s3.amazonaws.com/CTOdgNcmJ8d2sH10G7sDnhmNtjTxUop9oGtWxXpeoVt0ULqZdZzH9IcVxcgaxBG-y9cR2PDhPmsauHoI2DLZqO8YNHESHXc1W-QOBsp-4Y_S5IXJJ0hPmKCZYoNIsffZ.pnghttps://remnote-user-data.s3.amazonaws.com/CTOdgNcmJ8d2sH10G7sDnhmNtjTxUop9oGtWxXpeoVt0ULqZdZzH9IcVxcgaxBG-y9cR2PDhPmsauHoI2DLZqO8YNHESHXc1W-QOBsp-4Y_S5IXJJ0hPmKCZYoNIsffZ.png
        - 
    - If we are running low on data, or just want robust results, for example making sure we don't overfit Validation Set, we use K-fold Cross-validation that splits several fold our dataset, using different fold for training and testing one at a time.
        - https://remnote-user-data.s3.amazonaws.com/yJAO6DS1tnhovmp1qprgWFNmyIAKeq4ipngL2G4YI_dALez0L0gIV8UilIeWNxzxftjtJ_xakL7oMcHkEo8dX9zQeQH2fxx5Sqi-q7yAoqy-1AGDZ6G21hZ5IUFmlAgz.pnghttps://remnote-user-data.s3.amazonaws.com/yJAO6DS1tnhovmp1qprgWFNmyIAKeq4ipngL2G4YI_dALez0L0gIV8UilIeWNxzxftjtJ_xakL7oMcHkEo8dX9zQeQH2fxx5Sqi-q7yAoqy-1AGDZ6G21hZ5IUFmlAgz.png
        - 
    - 
    - Finding a good Hypothesis Function h is broadly about two things: appropriate Model Selection, and its Hyperparameter Optimization.
        - https://remnote-user-data.s3.amazonaws.com/c0L8XFjNLWg-uu8mUUFdRO-P9ZZBipVERt5-Lun1PF_gwOyo7XY_mn2OdIEOP40KJCy6XsG0OSZ5N8e-QBxgMQy0CyWn80IWkOV5-j3eYBM7YgFnQ-xPyi7GEcWZVmcj.pnghttps://remnote-user-data.s3.amazonaws.com/_f1prdVWp_CZvBJj1c4mYjZQiEuiG4SXqfgZBkDwP4cPom-HPNfjEsVt20L2O_CWZRYCnotXO-sJp-qEneSNX6Mak4_eEbDZE8-705JMb9mKdeTiy6cmZWcmVIg-uuvD.pnghttps://remnote-user-data.s3.amazonaws.com/_f1prdVWp_CZvBJj1c4mYjZQiEuiG4SXqfgZBkDwP4cPom-HPNfjEsVt20L2O_CWZRYCnotXO-sJp-qEneSNX6Mak4_eEbDZE8-705JMb9mKdeTiy6cmZWcmVIg-uuvD.pnghttps://remnote-user-data.s3.amazonaws.com/c0L8XFjNLWg-uu8mUUFdRO-P9ZZBipVERt5-Lun1PF_gwOyo7XY_mn2OdIEOP40KJCy6XsG0OSZ5N8e-QBxgMQy0CyWn80IWkOV5-j3eYBM7YgFnQ-xPyi7GEcWZVmcj.png
        - 
    - 
    - Model Selection
        - Two patterns of Validation Set Error and Training Set Error that occur in Model Selection:
            - https://remnote-user-data.s3.amazonaws.com/VWkDqAFaRVmxoNNhK_aiWFW7qf5Sznx8v8t0kvx697qe8KXk0I443V4mg92nV_nQ0RXawRyZsimcnlvgafp3NjyTzHCOt3uc9D-KskAbtQ4mKuHv-qUGgmPOl5_JcXH2.pnghttps://remnote-user-data.s3.amazonaws.com/VWkDqAFaRVmxoNNhK_aiWFW7qf5Sznx8v8t0kvx697qe8KXk0I443V4mg92nV_nQ0RXawRyZsimcnlvgafp3NjyTzHCOt3uc9D-KskAbtQ4mKuHv-qUGgmPOl5_JcXH2.png
            - https://remnote-user-data.s3.amazonaws.com/NtlQaEqNd3DAYmm6moQ5Dd5IQz4sgtHRutyGkH9YOv4M16OdHdsn4XhEv4h4i5FybRmCAWQgAwTIWxhShYVTrSvRkGla5-648I98WaPyjM1o7qzPvgC8gGw9bUEyg9SY.pnghttps://remnote-user-data.s3.amazonaws.com/lCFzvo0nw0rfudg3jo4g0drnuEMfPYpb2q74GiCzoasI2MUw1zyR2Z2CvnMlPEFvdeGvNi50NBe-pqq1M6oj7fncHba0BVGRwDTdE5lVFfY2zimwfwK3cZlKzJ5MGLr-.pnghttps://remnote-user-data.s3.amazonaws.com/lCFzvo0nw0rfudg3jo4g0drnuEMfPYpb2q74GiCzoasI2MUw1zyR2Z2CvnMlPEFvdeGvNi50NBe-pqq1M6oj7fncHba0BVGRwDTdE5lVFfY2zimwfwK3cZlKzJ5MGLr-.pnghttps://remnote-user-data.s3.amazonaws.com/NtlQaEqNd3DAYmm6moQ5Dd5IQz4sgtHRutyGkH9YOv4M16OdHdsn4XhEv4h4i5FybRmCAWQgAwTIWxhShYVTrSvRkGla5-648I98WaPyjM1o7qzPvgC8gGw9bUEyg9SY.png
            - 
        - Why there are different types of Validation Set Error and Training Set Error patterns?
            - It depends on how Model Class uses the excess capacity, and how well it matches the problem. 
            - We say Model has Interpolated the data when it represent all Training Set exactly (memorized is another word for it).
            - Some Model Classes never recover from Interpolating, like Decision Trees. For others, like Neural Networks, extra capacity means bigger Hypothesis Space, part of which has better suited Hypothesis Function to True Function f(x). (Some of such Model Classes are: Neural Networks, Kernel Machines, Random Forests, and Boosted Ensembles.)
                - https://remnote-user-data.s3.amazonaws.com/sRcM7PdekaGYeyiUZGnwICqLs91z7eLNb08NedXVOV5H9ePNkUYYABFlNfEteLGWqvHmwI4oStoqjRsvyThkDRi0K9MDNxhiDk9zA06P8VsyWMK1X1GZ6ZCylhId94yH.pnghttps://remnote-user-data.s3.amazonaws.com/SMyi8aV-OvNnI6QpG6SJDkdKPtk3Aq7X4W9HTthiIVpeBZiNVGHu-yZTU0Cf5fON4s9DtuTkmxUJaUUv8IVBDEyXxnp7K5ZoqqID9aQPgWjXHsD89gyP-yQOB81w2BDT.pnghttps://remnote-user-data.s3.amazonaws.com/SMyi8aV-OvNnI6QpG6SJDkdKPtk3Aq7X4W9HTthiIVpeBZiNVGHu-yZTU0Cf5fON4s9DtuTkmxUJaUUv8IVBDEyXxnp7K5ZoqqID9aQPgWjXHsD89gyP-yQOB81w2BDT.pnghttps://remnote-user-data.s3.amazonaws.com/sRcM7PdekaGYeyiUZGnwICqLs91z7eLNb08NedXVOV5H9ePNkUYYABFlNfEteLGWqvHmwI4oStoqjRsvyThkDRi0K9MDNxhiDk9zA06P8VsyWMK1X1GZ6ZCylhId94yH.png
                - 
            - 
        - There are different types of errors, False Positives (Type I) and False Negatives (Type II). Just as Utility-Based Agents have to maximize utility, Learning Agents have to maximize it too. 
        - Only in Machine Learning the tradition is to invert it, i.e. to aim to minimize the lost utility: Loss Function.
            - https://remnote-user-data.s3.amazonaws.com/Fv5ryd2wNRXUI9VuXxP87HaduMtucoorEoKcwVNzqe4m-iUSF8x3dDXjzKwFAIj1z6JmFwCsQnacvYFDk4E8FwVqkjsmV1jwNA07Vij_JI_XeSZLh5BI8eAvSP2sH-81.pnghttps://remnote-user-data.s3.amazonaws.com/3ORZv8yjoJWcXVa6vZb2FBgps7GYRu2x1A3s9PpyljcgNMUdS7kgoMvxXblCIPl5AGT7eGrEGD5wEa22ay-VvA1v-mWl1yiskaa18w5en51fulnpSVnv1D8FQUR9Wx3L.pnghttps://remnote-user-data.s3.amazonaws.com/3ORZv8yjoJWcXVa6vZb2FBgps7GYRu2x1A3s9PpyljcgNMUdS7kgoMvxXblCIPl5AGT7eGrEGD5wEa22ay-VvA1v-mWl1yiskaa18w5en51fulnpSVnv1D8FQUR9Wx3L.pnghttps://remnote-user-data.s3.amazonaws.com/Fv5ryd2wNRXUI9VuXxP87HaduMtucoorEoKcwVNzqe4m-iUSF8x3dDXjzKwFAIj1z6JmFwCsQnacvYFDk4E8FwVqkjsmV1jwNA07Vij_JI_XeSZLh5BI8eAvSP2sH-81.png
            - 
        - Generalization Loss, Empirical Loss 
            - https://remnote-user-data.s3.amazonaws.com/ZjNenADyAaqlRwgNNALfZh7QCc5d07vf6j0yBmp9hgQjT94qIZ1J7XmyZTmR_9LIVw1rnyBiH5iWBUO2StOsh_DGmGQeQRVl6Bk_gs6M9iNontvM9GKpFIp-Xiegax_7.pnghttps://remnote-user-data.s3.amazonaws.com/ZjNenADyAaqlRwgNNALfZh7QCc5d07vf6j0yBmp9hgQjT94qIZ1J7XmyZTmR_9LIVw1rnyBiH5iWBUO2StOsh_DGmGQeQRVl6Bk_gs6M9iNontvM9GKpFIp-Xiegax_7.png
            - 
        - 
        - We say that learning problem is Realizable is Hypothesis Space \mathcal{H} contains True Function f(x).
            - https://remnote-user-data.s3.amazonaws.com/4fIk0hO4OpPAEsSHZs-xwpJN0rmlgEyC6zrKQH-tm0HIhajmBD-lCjNIsWaTKUiNNJ6Th3RYhD25DzIZrzBHzig4WK_3SaEmAPmsXc_c8kGsodYzuLr0AO9j5LROuDpR.pnghttps://remnote-user-data.s3.amazonaws.com/4fIk0hO4OpPAEsSHZs-xwpJN0rmlgEyC6zrKQH-tm0HIhajmBD-lCjNIsWaTKUiNNJ6Th3RYhD25DzIZrzBHzig4WK_3SaEmAPmsXc_c8kGsodYzuLr0AO9j5LROuDpR.png
        - Variance is about the difference between Hypothesis Functions depending on the Training Set given. If problem is Realizable then with bigger Training Set Variance decreases towards zero.
        - True Function f(x) may be nondeterministic or Noisy ‒ it may return different values of f(x) for the same x. Noise cannot be predicted, it can only be characterized.
        - When True Function f(x) is complicated in a large Hypothesis Space, it can be Computationally Intractable to search all possibilities. So we search only part of the space that hopefully returns reasonable Hypothesis Function.
        - Small-Scale Learning, Large-Scale Learning
            - https://remnote-user-data.s3.amazonaws.com/Bnqk1WKaYV7_si7S6ieUgcCEVZQozcpvXl7zy7tam_7hgEzKvDiev01yEX6kxosdWyEBXEayXBgyqJNTV-diZfb1G6ZdazCgTgE7E_Gd33e-Gu0yEkVgVYrqOpM7EzyN.pnghttps://remnote-user-data.s3.amazonaws.com/Bnqk1WKaYV7_si7S6ieUgcCEVZQozcpvXl7zy7tam_7hgEzKvDiev01yEX6kxosdWyEBXEayXBgyqJNTV-diZfb1G6ZdazCgTgE7E_Gd33e-Gu0yEkVgVYrqOpM7EzyN.png
        - 
        - Regularization
            - Besides searching for model that just minimizes Empirical Loss (Loss Function over the Training Set), we can also minimize for function's complexity.
                - Is empirical loss just loss function over the training set?
                - https://remnote-user-data.s3.amazonaws.com/Q8BBd_ZVegar9Yy8ZS4NeecH40wxPBSBAv-8_YCstsa5m-al1r0FBs4rgyNJ7It6zZUfMT_CxW2wXmgqnMncn_Kr_vJ6jENWITCZBQQ8fo743uKZOTqOiOSwY8UsAXYU.pnghttps://remnote-user-data.s3.amazonaws.com/Q8BBd_ZVegar9Yy8ZS4NeecH40wxPBSBAv-8_YCstsa5m-al1r0FBs4rgyNJ7It6zZUfMT_CxW2wXmgqnMncn_Kr_vJ6jENWITCZBQQ8fo743uKZOTqOiOSwY8UsAXYU.png
                - 
            - Process of penalizing complex hypotheses is called Regularization ‒  we're looking for functions that are more regular!
            - Complexity measure of hypothesis functions is called Regularization Function. Its good choice depends on Hypothesis Space.
            - Another way to simplify Models is to reduce dimensions they work with: i.e. Feature Selection. (\mathcal{X}^2 Pruning is a kind of feature selection.)
                - https://remnote-user-data.s3.amazonaws.com/Ax5hOabEio22BSfk0GBR-pB4lrWxp9RI2ERzde0svX_N9wWMbneAc__So5RU_uPrHbC5EPjmKBZYF85767zgjWvcxyWNfyB5YOO6P7g9Rk5DOhoWAx1oIAzYtrBmbXOB.pnghttps://remnote-user-data.s3.amazonaws.com/bUb85l_N8ZvXC6TOl75PwnG3MipXl9Ywl5hGh9A0EeawQt7ResWy9l6SFhC78fOVA7MZLm_C9oEJ9MwrCl8fYAcnPgnchhy6pQdAYjOhlVc3_R8KhpuayEEEadq_GiXh.png
                - 
            - It is possible to have both Empirical Loss and Regularization Function (function's complexity) measured on the same scale: bits. (Minimum Description Length)
                - https://remnote-user-data.s3.amazonaws.com/5_PhzfnI2bULFkQCUAhcY2hqSvcU1Q-njCyErI_PARfWhPPLp71lxSdynFElOy1wR1VDbynmaYUOnVSKHaAp824glXMJHjQYiLNg0I-zuDVXKYsIQFP0qIeozhOUhsYZ.pnghttps://remnote-user-data.s3.amazonaws.com/5_PhzfnI2bULFkQCUAhcY2hqSvcU1Q-njCyErI_PARfWhPPLp71lxSdynFElOy1wR1VDbynmaYUOnVSKHaAp824glXMJHjQYiLNg0I-zuDVXKYsIQFP0qIeozhOUhsYZ.png
            - 
        - 
    - Hyperparameter Optimization
        - Hand-Tuning, Grid Search
            - https://remnote-user-data.s3.amazonaws.com/ZUJYQxVW2pmKxE8_9_0y9XyQqouBh5sNaATjOb7tCr8hlN05PTUS4hRb3ChTZysZHho7jdLFVaMBDU2_uTextc5x19i7TyFfdVh0dzsW_afeGbvBtm7BPY1jaOwRZ7bm.pnghttps://remnote-user-data.s3.amazonaws.com/emexf9qjhKYqJy896tutC3sVXzxnDwZT6y2wONNZTz4KDaqfcAYV0dTeyYo5f9bTcg9bo6UekGQXi4P5Z1HTChebf5HF_3CKfDD2K7sbH4uKVwLVKPozXyjIqJ3zdSTF.pnghttps://remnote-user-data.s3.amazonaws.com/emexf9qjhKYqJy896tutC3sVXzxnDwZT6y2wONNZTz4KDaqfcAYV0dTeyYo5f9bTcg9bo6UekGQXi4P5Z1HTChebf5HF_3CKfDD2K7sbH4uKVwLVKPozXyjIqJ3zdSTF.pnghttps://remnote-user-data.s3.amazonaws.com/ZUJYQxVW2pmKxE8_9_0y9XyQqouBh5sNaATjOb7tCr8hlN05PTUS4hRb3ChTZysZHho7jdLFVaMBDU2_uTextc5x19i7TyFfdVh0dzsW_afeGbvBtm7BPY1jaOwRZ7bm.png
            - 
        - Random Grid Search, Bayesian Hyperparameter Optimization, Population-Based Training
            - https://remnote-user-data.s3.amazonaws.com/jkBZQhD1Wf_f3a42w2LyNCEtZYjmo69DNY3N56pLwQrMtHWY6AYWKYUFJFTsWWT3uD5-TjAIwVmG07mMI5EflbW2kN2mzxnf9TA0AOVPxc75eKUA5UNaexeAdQN1p3ck.pnghttps://remnote-user-data.s3.amazonaws.com/jkBZQhD1Wf_f3a42w2LyNCEtZYjmo69DNY3N56pLwQrMtHWY6AYWKYUFJFTsWWT3uD5-TjAIwVmG07mMI5EflbW2kN2mzxnf9TA0AOVPxc75eKUA5UNaexeAdQN1p3ck.png
            - 
        - 
    - 
- 
- Theory of Learning
    - How can we be sure that our learned hypothesis will predict well for previously unseen inputs? That is, how do we know that the hypothesis h is close to the target function f if we don’t know what f is? These questions have been pondered for centuries, by Ockham, Hume, and others. In recent decades, other questions have emerged: how many examples do we need to get a good h? What hypothesis space should we use? If the hypothesis space is very complex, can we even ﬁnd the best h, or do we have to settle for a local maximum? How complex should h be? How do we avoid overﬁtting? How can we be sure that our learned hypothesis will predict well for previously unseen inputs? That is, how do we know that the hypothesis h is close to the target function f if we don’t know what f is? These questions have been pondered for centuries, by Ockham, Hume, and others. In recent decades, other questions have emerged: how many examples do we need to get a good h? What hypothesis space should we use? If the hypothesis space is very complex, can we even ﬁnd the best h, or do we have to settle for a local maximum? How complex should h be? How do we avoid overﬁtting? This
    - 
    - Computational Learning Theory, Probably Approximately Correct
        - https://remnote-user-data.s3.amazonaws.com/NgZiOHkEm66twrOFATr1X4sl4pALP0e3oo-qr3Lzq6AxvMs7_12qukD-O_jjo8-roYZnCqySbi2c9iY6IhHU6BB0PcrwZTJcL94qsh9mmbB7h24JaakeO6EQZRYRseBH.pnghttps://remnote-user-data.s3.amazonaws.com/mEe1jQ4nbHINWtrtBxkRnF1DfW_2mYcSN6FV2NA-PnevSv4HTxVtvBTTKFPE34reboL_qV86XKj2Xm32XCjU9Y-WTY-j1JrDzdD5QsjBwQ-eovyrpVTUGcoIRxqgPdDT.pnghttps://remnote-user-data.s3.amazonaws.com/mEe1jQ4nbHINWtrtBxkRnF1DfW_2mYcSN6FV2NA-PnevSv4HTxVtvBTTKFPE34reboL_qV86XKj2Xm32XCjU9Y-WTY-j1JrDzdD5QsjBwQ-eovyrpVTUGcoIRxqgPdDT.pnghttps://remnote-user-data.s3.amazonaws.com/NgZiOHkEm66twrOFATr1X4sl4pALP0e3oo-qr3Lzq6AxvMs7_12qukD-O_jjo8-roYZnCqySbi2c9iY6IhHU6BB0PcrwZTJcL94qsh9mmbB7h24JaakeO6EQZRYRseBH.png
        - 
    - PAC Learning, \mathcal{}\epsilon-ball, \mathcal{H_{bad}}, Space Complexity
        - https://remnote-user-data.s3.amazonaws.com/CFBHPodZdaYZBTZfaABYe2EQoCsF1YfRycNMOXba1nqMeHZOxpX4hBDoOq2SqYJ14oP6GYhhqZaPEYrHOweDbM-jw7SLq2sUD4peBEA_mU7jQewQ30b1SlMrXK6njGzX.pnghttps://remnote-user-data.s3.amazonaws.com/jXNamAee7X49_N6RN9QU6vedu_YgTiQN0JqTQ4PBdFuJEeZVyOPCHWVxB-v0kY6ZmNE7aEW5_2lYr0OCz27brsAO09jkuKn6nVcd1Op81IOkBpnROy8livKdDSGKHYIF.pnghttps://remnote-user-data.s3.amazonaws.com/jXNamAee7X49_N6RN9QU6vedu_YgTiQN0JqTQ4PBdFuJEeZVyOPCHWVxB-v0kY6ZmNE7aEW5_2lYr0OCz27brsAO09jkuKn6nVcd1Op81IOkBpnROy8livKdDSGKHYIF.pnghttps://remnote-user-data.s3.amazonaws.com/CFBHPodZdaYZBTZfaABYe2EQoCsF1YfRycNMOXba1nqMeHZOxpX4hBDoOq2SqYJ14oP6GYhhqZaPEYrHOweDbM-jw7SLq2sUD4peBEA_mU7jQewQ30b1SlMrXK6njGzX.png
        - 
    - PAC Learning ‒ a framework for asking: "How many examples do I need to learn a good hypothesis with high confidence?"
        - Two key parameters (see Space Complexity indent): 
            - ε (epsilon): How close to perfect your hypothesis needs to be (accuracy)
            - δ (delta): How confident you are (probability)
        - 
    - Space Complexity ‒ the number of training examples needed for PAC Learning.
        - AKA: the number of training examples required to statistically guarantee that Learning Algorithm will probably return an approximately correct Hypothesis Function.
        - AI explanation:
            - Space Complexity in PAC learning refers to the sample complexity — the number of training examples N required to guarantee that a learning algorithm will probably return an approximately correct hypothesis.
            - Here's the key result from your notes:
                - N \geq \frac{1}{\epsilon}\left(\ln\frac{1}{\delta} + \ln|H|\right)
            - What this means:
                - ε (epsilon): Maximum acceptable error rate — defines the ε-ball around the true function
                - δ (delta): Maximum acceptable failure probability — we want success with probability at least 1 - δ
                - |H|: Size of the hypothesis space
            - The intuition:
                - Any hypothesis outside the ε-ball (in H_bad) has error > ε
                - Such a "bad" hypothesis agrees with N examples with probability ≤ (1-ε)^N
                - This probability drops exponentially with N
                - We need enough examples so that with high probability (≥ 1-δ), all consistent hypotheses are inside the ε-ball
            - Key factors affecting sample complexity:
                - Smaller ε (wanting more accuracy)―need more examples
                - Smaller δ (wanting higher confidence)―need more examples
                - Larger |H| (bigger hypothesis space)―need more examples to rule out bad hypotheses
            - This bounds how many examples you need before you can be confident your learned hypothesis is approximately correct.
            - 
        - 
    - 
    - Even for Boolean Functions PAC Learning is infeasible because Space Complexity grows 2^n. This means 
        - 
        - 
    - Hypothesis Space \mathcal{H} even of Boolean Functions is insanely huge ‒ it grows doubly exponentially 2^{2^n}(see indent). 
        - Is there any kind of representation that is efﬁcient for all kinds of functions? Unfortunately, the answer is no—there are just too many functions to be able to represent them all with a small number of bits. Even just considering Boolean functions with n Boolean attributes, the truth table will have 2n rows, and each row can output true or false, so there are 22n different functions. With 20 attributes there are 21,048,576 ≈ 10300,000 functions, so if we limit ourselves to a million-bit representation, we can’t represent all these functions.Is there any kind of representation that is efﬁcient for all kinds of functions? Unfortunately, the answer is no—there are just too many functions to be able to represent them all with a small number of bits. Even just considering Boolean functions with n Boolean attributes, the truth table will have 2n rows, and each row can output true or false, so there are 22n different functions. With 20 attributes there are 21,048,576 ≈ 10300,000 functions, so if we limit ourselves to a million-bit representation, we can’t represent all these functions.
        - AI explanation:
            - Even for simple Boolean functions, the hypothesis space is absurdly massive - growing doubly exponentially (2^2^n).
            - This creates two major problems:
                - Representation: You literally cannot store or enumerate all possible hypotheses
                - Search: You cannot brute-force search through all possibilities to find the best one
            - So machine learning is fundamentally about smart navigation strategies:
                - Using inductive biases (assumptions about what makes a good hypothesis)
                - Employing efficient search algorithms (gradient descent, tree search, etc.)
                - Choosing restricted hypothesis classes (linear models, decision trees, neural nets) that can't represent everything but can represent useful patterns efficiently
            - The trade-off is always: more expressive hypothesis class = harder to search and more data needed to learn reliably.
            - 
        - 
    - This number is huge, it demonstrates why it is impossible to represent all Hypothesis Space \mathcal{H} with a compact representation, say million bits.
    - 
    - 
    - (Boolean Functions ‒ functions that take boolean inputs and produce boolean output.)
        - Boolean functions are functions that take Boolean inputs (true/false values) and produce a Boolean output.
        - With n Boolean attributes (input variables), you can construct a truth table with 2^n rows - one for each possible combination of input values.
        - For example, with 3 attributes:
            - 2³ = 8 possible input combinations
            - Each combination can output either true or false
            - Total possible functions: 2^(2³) = 2^8 = 256 different Boolean functions
        - The passage is highlighting a fundamental limitation:
            - With 20 Boolean attributes, there are 2^(2²⁰) ≈ 10^300,000 possible functions
            - This number is astronomically large - far exceeding the number of atoms in the universe
            - Even with a million-bit representation scheme, you cannot represent all these functions
        - The key insight: No single representation scheme can efficiently represent all possible Boolean functions, because the space of all functions grows doubly exponentially (2^2^n) with the number of inputs. This means we need to be selective about which functions we can learn or represent in machine learning. 
        - 
    - 
    - 
    - So we either need to severely limit it (Model Selection), or efficiently navigate it (Hyperparameter Optimization), while still needing more example data and search compute.
    - 
  
