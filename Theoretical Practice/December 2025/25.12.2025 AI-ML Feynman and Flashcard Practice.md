# Goal
I have gone through a lot of material in the last few weeks, but was slacking on practicing it (i.e. properly integrating) through flashcards and feynman explanations. This and next few practice sessions should fix that. I aim to go through all AI/ML topics.

## Questions

# Debrief
1. I feel solid about my panoramic view of both computers, programming, ai, and ml.
2. Troubles with recalling types of environments. Sequential, dynamic, continuous, non-deterministic...
3. Mixed up how we can representat environment with how agents internally represent it.
4. Completely forgot PEAS, but it is useful. 

3. Not sure as much about types of agents.

# Notes

So we invent computers, which are tools for transforming information.
(My boy Charles was really tired of same math tasks, and was a genius to invent a computer, but horrific project manager and failed to build it :( )

The most fundamental model you have to always keep in mind is:
**inputs => transformations => outputs**

That's what computers do 

As a tool, computers need a way to take in inputs and give out outputs I/O devices, they need memory (RAM, ROM) on which to store those inputs, and head (CPU, GPU) through which to change them, software i.e. instructions on how exactly to change them, and power to power it all (sorry for duplication).

Software engineer is a guy who writes useful trasnformations for computers to do.

Computers turn out to be a very powerful tool because they manipulate information, which itself turns out to be a very fundamental thing in the universe.

So software engineer is in command of a pretty powerful tool!

Coming back to our inputs => transformations => outputs model, SE needs to specify data structures for inputs, and how to manipulate them i.e. algorithms. That's all what SE's do.

Now for the sake of time saving let's skip some parts regarding programming languages, like what kinds can they be, and why you'd prefer one kind over the other etc.

--

Let's say we have this coder that writes down by hand instructions to computer. He finds some problem, he then uses computer to solve it and everyone is happy.

But now we need to talk about some type of problems our lovely coder is having hard time solving. For example, he wants to write an instruction so computer could identify whether an image has a cat or not. 

Easy problem to describe, but in practice impossible to solve for our coder. Why? Because try for a second writing an instruction based on the picture. Many black pixels put together to give two corners and circles probably a cat? Practically impossible. (I don't say in principle, but in principle this can be solved...)

We can call this hand-crafted explicit type of programming: explicit coding.

So how do we solve this type of problems? !

These are actually pretty important problems, think everything from image identification, language processing, sound detection and so on... Would be very useful to solve them!

Our absolute beast of a man Alan Turing already back in 1950s days had an idea: what if we create a learning algorithm, which could learn how to do those tasks on its own.

Sure thing we can't specify those transformations, but we could possibly specify some algorithm that could find those transformations. And that lovely idea is the birthplace of machine learning.

--

Machine learning is interested in finding this universal learning algorithm that could learn how to do any task with very little training data required, generalize really well, and be compute efficient. One example of such learning algorithm in nature would be whatever humans have in their heads. Compared to our best ML techniques our brains are astonishing at how little training data we need, how well we generalize, and how EXTREMELY compute/energy efficient we are! (Though we have our own limitations, like not perfect memory, slow cycle time and so on.)

ML is a sub-field, and it is studied usually together with the whole field of Artificial Intelligence.

Artificial Intelligence indeed sounds very cool, but all it is about is another type of programming computers. It is different from traditional programming only in that it uses slightly different instructing techniques and it tries to solve a different class of problems like language processing, image identification and so on.
Which makes sense -- you use different approach to solve different type of problems that traditional programming (explicit coding) can't do.

And while AI has many subfields, the idea of finding a learning algorithm whom you teach transformations you can't specify by hand is AI's gem, and this is what machine learning (deep learning...) focuses on.

Because the field is called Artificial Intelligence it attracts such questions like: What is intelligence? What it means to understand? What is consciousness? and so on. As if your learning algorithm finds sufficiently complex transformations, and can do sufficiently complex stuff like identifying cats, maybe it understands what cats are, and if it understands, then there must be someone there, someone intelligent, someone conscious dare I say?

Those are of course interesting questions, but people spend too much time debating them when in fact we just don't have any good theory behind them. Science is sadly too far to answer those questions well.

--

So let's talk about AI, the panoramic view of AI dare I say.

First, AI is just another way of coding, so some things will not change when we're doing an AI project, or traditional coding project. 

First we start with understanding what is the problem in our real-life, then we try to strip it down to its basics so we can use our computers to find answer and then translate it to our real world.

Let's consider a problem that I want to drive from SF to NY, and I need shortest path to it. 

Well, say we want to use computers, maybe AI. How can I use them to help me solve this problem?

Do I upload all road images of US and tell it to navigate? Here we realize a crucial step. We need to simplify our real-life problem while keeping simplified version still valid. We have our real-world environment, and now we need to create a simplified, valid version of that world, i.e. representation, for computer to navigate.

So we could simplify our real-life problem for example by saying that I'm just interested in main cities I need to drive through and not exact road directions. The way we could represent that for computer is to create a graph of US cities with how long it takes to drive between them in paths.

This is our representation of our real-life problem, in AI this would be called enviroment; in traditional programming this is data structure.

Now, we'd like to navigate that graph with our computer to show the shortest path between two points. This is the transformation we want our computer to do. The input is city graph, the transformation is searching for the shortest path between SF and NY, and where the desired output is the path between the two points.

So we need to write a transformation for that. In AI (aima) this transformation would be called an agent that navigates enviroment (city graph) to find the shortest path. In traditional programming this is algorithm manipulating data structure for the desired output. 

AIMA presents AI as environments that agents need to successfully navigate. And depending on what type of environment is, we create different agents. Environment is a simplified, valid representation of our real-life problem, which, if successfully navigated by our agent then can be used by us to solve our real-life problem.

Navigating graphs is the simplest of AI programs/ environments which is called search. 

--

To explain AI deeper, let's talk about the types of environments there are, and the types of agents we can build. Then I'll present the main sub-fields of AI, briefly talk about each, and then describe ML/DL which is the most interesting sub-field and the one I'm focusing on.

ğŸ”´ => I forgot about PEAS, which is a useful idea. 
PEAS is a way to break down both the environment agent operates, what agent we use, and what goals it has:
1. Performance Measures -- how we'll measure how good agent does.
2. Environment -- that agent navigates
3. Actuators -- what agent has available to them to steer the environment they operate in.
4. Sensors -- how agents gets information about its environment.


Types of environments:
1. Sequential vs (episodic? periodic) => I think I'm mixing it with also long-term environments, where your past actions influence the future ones. 
ğŸŸ¡ => So, episodic vs sequential is about whether your past actions influence the future ones, or it is a new closed system every time. Playing chess is sequential, detecting mistake in produced part at an essembly is episodic (you evaluate each part one at a time).
ğŸŸ¡ => Static vs dynamic -- whether environment changes while agent is deliberating.
ğŸŸ¡ => Discrete vs continuous -- how environment states are handled, how time is handled, and how perceptrons and actuators of an agent work.

2. Fully observable vs partially observable -- do we have ALL the information about the environment, or some of it hidden from us? i.e. fog of war. In chess we know everything, in poker we don't. With partially observable environments agents need to be good at information gathering to make successful decisions.
3. Multiagent vs single-agent, and then cooperative vs competitive in multiagents. Poker is multiagent competitive, finding the shortest path in the city graph is single agent, and autonomous taxi-driving is multiagent cooperative.
4. ğŸ”´ => having hard-time recalling many other types of environments, and this is pretty important.
4. ğŸ”´ Deterministic vs Non-deterministic -- whether the next state in environment completely depends on agent's actions, and nothing else. Chess and poker are non-deterministic. Navigating city graph is deterministic. (And when we deal with known probabilities, like 25% it will rain, then it is sequential.)
5. ğŸ”´ Known vs Unknown -- whether the "laws of physics" or rules by which environment operates in completely known to the agent. Whether they are encoded into the agent. You can encode chess rules into a chess agent, but it is harder to do that for image identification agent.

When choosing what environment our agent operates in we can make it simpler or more complex. The most complex environment is the one that accurately represents our real world. Life is a partially-observable, non-deterministic, unknown, sequential, continuous, multiagent (can be both cooperative and competitive), and dynamic environment.

--

Agent can be online vs offline. Offline is when it computes solution and then executes it and nothing will change, it can do it "blindly" and it will work. Online is when environment might change, so agent need to adapt on the go.

Knowledge-based agents have internal representations about the environment and can reason through them. Learning-based agent can learn on its own about its environment and adapt its actions to achieve its goals.

Goal based vs utility based agents. In goal based they have binary: Is the state the goal state or not? With utility, states are analogous, some are better than others and we can quantify by how much. We can also use probabilities to consider how likely one event is other the over. Together using utility theory and probability theory yields us decision-making theory that agents use. Expected value is multiplying the two to make decisions about which states to pursue.

Agents can be grouped differently. First is by how they internally represent environment: is it atomic representation (black box), factored representation (variables with values), structured representation (recursion of factored representation where each state can have graph of connections with variables and values.)

â“ => or is this how environments in general can be represented, and not about internal representation of agents?



