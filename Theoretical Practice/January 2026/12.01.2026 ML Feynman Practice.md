# Goal
I find feynman explanations to be better at integrating knowledge than chapter exercises, certainly theoretically. So today I want to go over ML explaining what I can remember, finding and fixing weak points.

# Debrief
1. I like that in explaining computers and AI I start with the problem of SF to NY to illustrate simple valid environment idea. In general it is useful to have an example as a backbone for explanation.
2. I like explaining AI as SE, talking that different problems require different approaches so we group them differently. I like mentioning understanding, consciousness and intelligence as lacking good theories, and why they are part of AI field.
3. I like right away mentioning Alan 1950s insight, especially when explaining implicit vs explicit coding.
4. I like the smooth transition between explaining SF to NY problem with simple valid representation and environment-agent models. 
5. âš ï¸ I have done a lot of practice of panoramic computers/coding/ai/subfields/ml view. In the future I should focus more on explaining subfields and insides of ml. Only briefly and quickly talking about panoramic stuff since I have practiced it so much.
6. When talking about model-based agents then talk about ways to represent environments: atomic, factored, structured.
7. I didn't talk about multidiscriplinary nature of AI, or its history. Is there a way to integrate that? This is panoramic, so maybe that is improvement for later.
8. Didn't mention anywhere data, algorithms, compute parts. 
9. Call AI subfields correctly: search; logic, knowledge, reasoning, and planning; uncertain knowledge and reasoning; machine learning; deep learning ...
10. Static vs Dynamic (having time to think without environment changing), Deterministic vs Non-deterministic.
11. Call out model-based agents, simple-reflex based agents.
12. âš ï¸ Will give sub-heading to explanations, too messy and helps to structure my thoughts.
13. âš ï¸ Mostly butchered recalling sub-fields. Need more practice.
14. Search in simple, complex environments; constraint satisfaction problems, adversarial search. state-space search vs path finding search. local search as important part of complex environments (gradient descent is a type of local search).
15. With constraint satisfaction problems the main idea to remember is that in CSPs environment is represented as factored, while in simple and complex environments it is represented as atomic. (which makes all the sense)
16. Logic-Based Agents Feedback: I mistook first-order logic and propositional one. First-order is the more expressive one. Then better say knowledge representation languages than just logic. Talked about knowldege bases, sentences, inference, that's good. Didn't mention we can use these "logic-based" programs for planning. Ontological engineering! (Sounds so cool, boi...)
17. And actually as feedback I think this is around the thing I should be remembering. Remember it is about adding likelihood to events in internal representations and utility, and this is still heavily hand-crafted agents. The rest I could learn later.


### Questions
1. Any transformation of universe you'd like to do can be boiled down to information transformation. â“ => is that so?
2. â“ Good question is whether we can create a more complex environment that universe itself, or it will be like trying to compute something too complex for the universe. (But also good reason life is the most complex environment we navigate is because why bother navigating more complex environments, it's a waste of resources.)
3. 

### Answers
1. Somewhat yes. Only let's not forget about substrate that information is on, i.e. matter. Maybe information is even more fundamental than matter.
2. 

# Feynman Explanation

### AI is Coding, Explicit vs Implicit Coding

AI is fundamentally about software engineering. We want to instruct computer to do some task. It is different from traditional SE because of problems we are trying to solve, and thus different techniques we're trying to use. Generally AI is trying to make computers do hard stuff like speech recognition, image recognition or creation, and language processing, also robotics. 

To do those things we can't use traditional SE techniques, try writing a program that identifies bees on an image with if/else statements. In principle it is possible, in practice it isn't. So, we need a new approach. Already in 1950s this problem was clear to Alan Turing: it's impractical to use a bunch of rules to solve these tasks. Hence, he proposed creating a learning algorithm, that could learn those tasks, this way the program is much simpler and ideally it would learn all these complex tasks. That's a remarkable insight for his time, and personally that elevate Turing for me into the realm of Newtons, Maxwell's and Einsteins, but I diverge.

So we have two approaches, one of traditional SE with a bunch of explicit rules, and another of learning algorithm that learns things. It is useful to group those, I call it explicit coding and implicit coding respectively.

AI, at its core, is about this implicit coding, where we create a, hopefully, universal learning algorithm that can learn any task we'd like very efficiently. One example is whatever humans have in their brain that helps us learn how to drive, speak, draw, do math and so on. 

AI has different subfields, one of which is ML, which is about creating this learning algorithm. Others are closer to explicit coding, like search, knowledge representation, and uncertainty and probability engineering. Implicit vs explicit coding isn't binary, its more accurate to think of it as a spectrum.

ðŸŸ¡ => Poor naming of subfields, have to fix that. It is: search; logic, knowledge, reasoning, and planning; uncertain knowledge and reasoning; machine learning; deep learning; ...

Because AI aims to make computers solve really hard problems like speech, image, and language processing it is fair to ask: Are those computer intelligent then? And if they can do those tasks, do they understand? And if there's someone to understand, is it possible that someone is there? Perhaps someone conscious? Those very interesting questions also happen to be part of AI. You could be dragged into endless debates about their nature, but here's my take. We don't have good theories behind what constitutes conciousness, understanding, or intelligence. We have rules of thumb. Someone will come along and solve those mysteries, maybe AI itself, but before that it is closer to a huge drain of time. Is a huge csv file conscious? Hell, I'd say no, but when you see what it can do you're not so sure. (There's a more universal lesson here, but it is a sidetrack. As David Deutsch argued, you want to look at the explanation of something, not at what it does. So judgement of whether a huge csv file is conscious should be based on our explanation (theory!) of what consciousness is, not on what this csv file can do. Anyways.)

All that is to say that even though understanding, intelligence, and consciousness are all parts of AI, don't get sidetracked, and remember that it is about instructing computers to solve problems. Different problems compared to traditional SE, which requires different instructions: explicit vs implicit coding (collection of rules vs a learning algorithm).

---

### Briefly on Computers

Also I didn't talk about computers, and they're a big deal in our conversations since we're instructing them. Computer is a tool, just like hammer that was invented by us humans. (Creating and using tool is our shtick by the way.) Only instead of hitting something, like hammer, computers are about transforming information, from inputs to outputs via our instuctions. 

Turns out, this is a pretty powerful thing, as information is something very fundamental in the universe, and if you can transform some right information you then can leverage it and have enormous physical impact. 
Any transformation of universe you'd like to do can be boiled down to information transformation. â“ => is that so? => kind of yes. (matter is a substrate for information.)

It was created by Charles Bubbage, he got tired of differential equations, maritime navigation in 18th century England, he was a bad project manager...

To transform information we have: input to take in what to change, memory to store it, head to change memory and do transformations on it, instructions (software) we wrote on how to change inputs, and outputs on giving back changed inputs. Oh and power for it all to work.
Binary vs analog error correction, memory is just a big table, ram vs rom think table vs side cabinet, cpu vs gpu different head types, ...

The most important loop you have to keep in your head is: input => transformations => output.

Ok, enough computer recalling. (ðŸŸ¡ Also don't forget, data-structures + algorithms...)

---

### SF-NY, Environments and Agents

So, let's get more concrete. Say we have a problem of getting from SF to NY, and we want to find the most optimal path for a car. This is a problem. And I say how great computers are as a tool: How can we use computer to help us with solving that problem?

Remember the loop: input => transformations => output

We need to give computer input about our problem, then write instructions on how to find the optimal path which it then can return to us as an output.

What input should we give to computer? We could make videos of all roads in US, in all directions, then upload it and through image recognition and some other algorithm ask to create a map of us, navigate it, and find the optimal path between the two. That's one way. Obviously it won't work and is not just an overkill for what we're trying to do but it simply won't work. 

Why am I spending time saying the obvious? To highlight next insight: we need to create simple, valid representation of our problem. And then we'll use it as something computer could navigate. And, if it navigates it successfully, it will produce insight which we then can apply in our real-life.

Simple because our computers are not so powerful as to freely navigate real world, valid because we'd like to apply it to real world afterwards. But even if our computers would be so powerful, why would we want to waste computation and energy giving them the most complex convoluted version of the thing, when solving a simpler representation will solve our problem just as fine!

So, this brings us to mental models AIMA talks about and I like it. 

We have environment that computer needs to navigate, which is simple and valid representation of our problem. For example the simplest version could be a graph of cities with 1m population or more in US where connections have info about distance between cities. 

Then we have the program we write to navigate that environment hopefully successfully. In AIMA they call it an agent, any program is an agent. Program that navigates a graph of cities, or llm chatbot are both agents, just one is navigating a much more complex environment.

---

### Environment Types

So we have our problem, we have two parts we need simple, valid environment, and agent that navigates it. 

Depending on the problem we have, we'll have different complexity of environments, and depending on environments we'll need different programs to successfully navigate them.

By talking about different types of environments we can have, and different programs/ agents we can use to solve them, we can get a good overview of AI subfields. One of which is ML, into which we'll go more in depth.

Types of Environments:
1. Discrete vs Continuous -- broadly everything from percepts, actuators, the world states.
2. Sequential vs Episodic -- do past actions matter?
3. Online -- when environment is changing even when you're thinking of actions ðŸŸ¡ => static vs dynamic. => online is about whether the agent can "close their eyes" and navigate environment blidly to their goal when they have figure out the solution.
4. single vs multiagent (cooperative vs competitive) -- finding path on a graph vs self-driving vs chess
5. Fully observable vs partially observable -- do we know everything that is happenning in the environment, do we know all there's to know? think chess vs poker.
6. Known vs unknown -- Whether laws of physics for environment are known to program, or they need to figure them out. We could code possible moves of chess, then it would be known.
7. Probabilistic vs Nonprobabilistic (vs stochastic when we know exact percentages.) -- when only our agent's actions determine next environment states or there's something else. ðŸŸ¡ => Deterministic vs non-deterministic.

ðŸŸ¡ => I think this is all of the types, but it takes me quite some effort to recall it. 

Real world is the most complex environment type, it is: continuous, sequential, online, multiagent, partially observable, unknown, non-deterministic, dynamic.
â“ Good question is whether we can create a more complex environment that universe itself, or it will be like trying to compute something too complex for the universe. (But also good reason life is the most complex environment we navigate is because why bother navigating more complex environments, it's a waste of resources.)

---

### Agent Types

Types of Agents:
1. Goal-based agents -- binary goals
2. Utility-based agents -- decision theory = probability theory + utility theory.
3. Knoweldge-based agents -- it is useful to have representations about the environment, and think through them before acting. Both explicit and implicit coding.
4. Learning-based agents 
ðŸŸ¡ => Forgot simple-reflex agents -- say those that navigate graph, and instead of knowledge-based agents we can call them model-based but I don't think this is as important.
ðŸŸ¡ => didn't talk about learning agents internals, but that's okay. 

Parts of agents/ programs: 
- percepts to learn about the environment
- actuators to navigate environment
- program that takes in percepts and based on some computation does smth with actuators
ðŸŸ¡ => not sure whether that's all. I know about the program function vs slightly different thing, but still. => agent program vs agent function. 

There are different ways to represent the environment!
Atomic -- black boxes connected with each other.
Structured (ðŸŸ¡ => this is factored, vice versa) -- nodes connected with each other where node has variables with values.
Factored -- recursion, where node can have graph of nodes inside itself.
ðŸŸ¡ forgot to talk about environment representation on my own, also mixed up names

---

### Search

Okay, these are environment and agent types. Let's talk examples to illustrate AI subfields. 

First we have fully-observable, deterministic, single-agent environments. For example, finding optimal path on a graph between two points. Just like in our simplest case of SF to NY.

The main idea in such problems is whether we have a heuristic function that can help us telling how far are we from our goal, the better h is, the better our search will be. Search with h is called informed, search without is called uninformed. Uninformed is simple, we either open first breadth node (breadth-first search), or go as deep as possible depth-first search. Informed we either use greedy just maxxing for h, or add something like N of steps made as a penalty. 
ðŸŸ¡ => how true is that last part?

We can also search environments where we don't care about the path, but the final state. For example placing hospitals optimally on a map. Or doing gradient descent of finding the lowest point on a graph where x-axis is weight values, and y is performance on the loss function.

I differentiate between these types of searches as path-search and pathless-search ðŸŸ¡ ... pathless? What's the right name for it.

Search is the first type of AI subfield. Mainly because it deals with the simplest environments, and you'll use techniques you study here in other subfields, like gradient descent.

ðŸ”´ => Forgot to talk about two out of four main parts of search: constraint satisfaction problem, adversarial search.

In general in search we have:

#### Search in Simple Environments
Path finding search. 
Fully observable, episodic, deterministic, single-agent, static environments.
Two main parts: uninformed search, and informed. All about heuristic function.

#### Search in Complex Environments
Multiagent -- chess. Non-deterministic -- poker. Partially observable -- poker.
ðŸŸ¡ => kind of wrong, as this is all for adversarial search, but good idea of just looking one by one at different environment types and making them more comlpex.
-
Non-deterministic, partially observable, unknown, continuous states.
Not pathless, but state-space search vs path finding search.

Local search/ state-space landscape as an important part.
Going in depth on other sub-topics is not priority atm.

#### Constraint Satisfaction Problem
The main idea is that in CSPs environment is represented as factored, while in simple and complex environments it is represented as atomic. That's what I want to remember.

#### Adversarial Search
all the examples I have given in complex environments...

Not a lot to take out, just that all multiagent environments, specifically competitive ones, should go here.

---

### Logic, Knowledge, Reasoning, and Planning

Logic-based agents/ knowledge based agents
ðŸŸ¡ => Logic, Knowledge, Reasoning, and Planning

We need some shared way to represent knowledge. It can be seen as statements about connection between things. First order logic, logic in general...

Well, what would I remember.
I would remember first-order logic.
Inference with First order logic.
What is the other type of logic? hm... That I don't remember. ! Propositional logic! One that allows interaction between objects, right?...
Though I presume we also have a subtopic about its inference. Inference with Propositional Logic.
And I presume there's a topic on ontology building, knowledge base engineering something like that. 

But let me actually explain what this sub-field of AI is about. Basically this is our first interaction with model-based agents. Agent that have internal representation of the environment, which they use to reason before acting. The insight is simple, it is useful to know stuff, and reason about them before acting, let's build agents that can do that. Logic-based agents are the first attempt. Why?

Because we need some robust way to represent knowledge and reason about it. Logic does exactly that. It is an agreed upon convention, there are different types of logic that allow different things, like first-order logic vs propositional logic. The main gist is that you have objects and then you have relationships between those objects. The holy grail everyone is pursuing in this subfield is some explicitly defined language that is also universal enough to be applicable for many problems. So far no success. 

So the way it works, is by engineer creating axioms, or initial knowledge based, then defining ways program can do inference and reason about those statements to derive other new useful statements. And there's a huge variety in what language/ logic to use, how to do inference, and what to put in when constructing initial knowledge base. None of that will I study in more depth than this ðŸ™‚

ðŸŸ¡ => So. I mistook first-order logic and propositional one. First-order is the more expressive one. Then better say knowledge representation languages than just logic. Talked about knowldege bases, sentences, inference, that's good. Didn't mention we can use these "logic-based" programs for planning. Ontological engineering! (Sounds so cool, boi...)

---

### Uncertain Knowledge and Reasoning

Uncertainty and probability based agents
ðŸŸ¡ => Uncertain Knowledge and Reasoning

Ok, uncertainty. The main idea is that not all knowledge is absolutely certain. It is useful to have gradation of certainty, and likelihoods. When something is 1% likely to happen it doesn't make sense to spend same resources planning for response as in cases that would happen with 40% chances.

So now we want both to give probability to our statements, and to possible actions that could happen when internally representing environment. We could also use utility theory, and decision theory = utility theory + probability theory. This way our agent would choose actions with highest expected value.

We would still design our agent mostly by hand, something we'll get rid of in ML part.

Frankly I don't remember much more than that for this subfield.

And actually as feedback I think this is around the thing I should be remembering. Remember it is about adding likelihood to events in internal representations and utility, and this is still heavily hand-crafted agents. The rest I could learn later.

---

### Machine Learning

So, now the machine learning subfield. Were interested in creating a learning algorithm that will learn transformation, not us coding them exactly step by step. If in explicit coding case transformations are found by coder: input => transformations => output. In implicit coding it is: input => learning_alg(transformations) => output.

In explaining ML it is useful to separate it into three parts: Data, Models, Evaluation. And right away get a feel for how steps of an ML project looks like:
1. Understand the problem. Just what actually are we trying to achieve. Crucial step before doing any coding.
2. Data. Basically find, and prepare the data to be used by the model. Here you spend most of your time.
3. Model. Find the right model and train it.
4. Deployment. Evaluate your model, make sure you're solving the problem, deploy it in production, present the solution.

Based on the ML Model we define, it defines the hypothesis space. 
Data is used as feedback, we use it to search hypothesis space. If this H is too broad, we'll need too much data and too much computations, if too narrow we might miss working hypothesis function that successfully maps inputs into outputs.

The loop all ml algorithms follow is: 
1. Make a guess. 
2. Get feedback.
3. Update your "guessing-machine" (i.e. weights) accordingly.

Data is basically the whole world for the model, it is the representation of the problem, the simple valid representation, or the environment it manages.

We have supervised, unsupervised, and reinforcement learning parts.

All ml models can be grouped by several dimensions:
1. online vs offline learning -- can you add a few training examples over time and slightly tweak the model, or you have to retrain it entirely from sctrach
2. Model vs instance based -- do you create some model, like linear regression, or do you use directly training examples to come up with answers like knn.
3. supervised vs unsupervised (also semi-supervised) -- are you given the desired outputs as part of training for feedback or not?

---

Let's talk supervised models specifically.

It is all the linear, polynomial, logistic functions.
knn.
decision trees.
support vector machines -- distance between points
ensemble learning -- collections of models
online learning -- recommenders? not sure.

--

More on ML. 

One question I had: Why it takes so much god damn data to train those models, when for humans it doesn't. The answer is because we're running a much more efficient algorithm, and because we have decades of experience which we have used to build useful representations of phenomena. Most of computation these models use is for building representations of phenomena, only at the end, like cherry on top they figure out how to transform them. You can retrain existing neural net to do different task if it is similar on a very small number of data because it already has built all the needed representations.

I also had a question why traditional SE is so different from AI, i.e. implicit coding vs explicit coding: Why there's no data collection step in implicit coding? It is becuase it is done by humans, by the coder, it uses a more efficient algorithm, yet it still needs to collect information about the problem, to understand it, to search for solution/ transformation. So fundamentally explicit coding is doing the same as implicit, it is just that for the first one the problem understanding part is hidden, or building representations of the problem.

Computers have roughly 10 million times faster cycle time than brain...

---

DL... wip

---
